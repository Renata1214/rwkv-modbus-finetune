{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702b2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c773a862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? True\n",
      "CUDA device count: 8\n",
      "Current device ID: 0\n",
      "Current device name: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"Current device ID:\", torch.cuda.current_device())\n",
    "print(\"Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a0f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060f000000060005fffdff00</td>\n",
       "      <td>060f00000003008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01b7000000060005fffdff00</td>\n",
       "      <td>01b700000003008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05420000000d0010ec88000306831883180000</td>\n",
       "      <td>054200000003009002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005f0000000d0010fffd000306ffffffffffff</td>\n",
       "      <td>005f00000003009002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05c40000000b00100026000204ffffffff</td>\n",
       "      <td>05c400000006001000260002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    query                  response\n",
       "0                060f000000060005fffdff00        060f00000003008502\n",
       "1                01b7000000060005fffdff00        01b700000003008502\n",
       "2  05420000000d0010ec88000306831883180000        054200000003009002\n",
       "3  005f0000000d0010fffd000306ffffffffffff        005f00000003009002\n",
       "4      05c40000000b00100026000204ffffffff  05c400000006001000260002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#Observe final Dataset\n",
    "df_modbus = pd.read_json(\"modbus_dataset.jsonl\", lines=True)\n",
    "df_modbus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba810a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b38e9becb4686bdd309977bfeca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)WKV-5-World-0.4B-v2-20231113-ctx4096.pth:   0%|          | 0.00/924M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /home/re2230/.cache/huggingface/hub/models--RWKV--rwkv-5-world-all-pth/snapshots/d48d1c54cf32cfdc13fca3c767998a0bf3eef8b6/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"RWKV/rwkv-5-world-all-pth\",\n",
    "    filename=\"RWKV-5-World-0.4B-v2-20231113-ctx4096.pth\"\n",
    ")\n",
    "\n",
    "print(f\"Model downloaded to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a658f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/re2230/.cache/huggingface/hub/models--RWKV--rwkv-5-world-all-pth/snapshots/d48d1c54cf32cfdc13fca3c767998a0bf3eef8b6/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1831181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mode': 'bone', 'r': 32, 'load': ''}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.loads('{\"mode\":\"bone\",\"r\":32,\"load\":\"\"}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f19e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/re2230/RWKV-PEFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /home/re2230/RWKV-PEFT/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c34393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/re2230/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mre2230\u001b[0m (\u001b[33mre2230-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8070271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/re2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /home/re2230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6e1d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afecac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 STDOUT:\n",
      " [2025-05-27 10:58:57,088] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "########## WKV OP           cuda               ##########\n",
      "########## WKV OP           cuda               ##########\n",
      "########## WKV OP           cuda               ##########\n",
      "\n",
      "########## FUSED OP    False          ##########\n",
      "########## FUSED OP    False          ##########\n",
      "########## FUSED OP    False          ##########\n",
      "\n",
      "RWKV_MY_TESTING x052\n",
      "ninja: no work to do.\n",
      "RWKV(\n",
      "  (model): RWKV5(\n",
      "    (emb): Embedding(65536, 1024)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=1024, out_features=65536, bias=False)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "[2025-05-27 10:59:00,382] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.03962540626525879 seconds\n",
      "Rank: 0 partition count [1, 1] and sizes[(8581120, False), (24576, False)] \n",
      "\n",
      "Training: |          | 0/? [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] \n",
      "{'zero_allow_untested_optimizer': True, 'zero_optimization': {'stage': 2, 'contiguous_gradients': True, 'overlap_comm': True, 'allgather_partitions': True, 'reduce_scatter': True, 'allgather_bucket_size': 200000000, 'reduce_bucket_size': 200000000, 'sub_group_size': 1000000000000}, 'activation_checkpointing': {'partition_activations': False, 'cpu_checkpointing': False, 'contiguous_memory_optimization': False, 'synchronize_checkpoint_boundary': False}, 'aio': {'block_size': 1048576, 'queue_depth': 8, 'single_submit': False, 'overlap_events': True, 'thread_count': 1}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'gradient_clipping': 1.0, 'bf16': {'enabled': True}}\n",
      "\n",
      "\n",
      "Epoch 0:   1%|          | 1/100 [00:01<01:51,  0.89it/s]\n",
      "Epoch 0:   1%|          | 1/100 [00:01<01:51,  0.89it/s, lr=6e-5, sum_loss=4.440, loss=4.440]\n",
      "Epoch 0:   2%|▏         | 2/100 [00:01<01:04,  1.52it/s, lr=6e-5, sum_loss=4.440, loss=4.440]\n",
      "Epoch 0:   2%|▏         | 2/100 [00:01<01:04,  1.52it/s, lr=6e-5, sum_loss=4.530, loss=4.620, REAL it/s=5.130, Kt/s=2.630]\n",
      "Epoch 0:   3%|▎         | 3/100 [00:01<00:48,  2.00it/s, lr=6e-5, sum_loss=4.530, loss=4.620, REAL it/s=5.130, Kt/s=2.630]\n",
      "Epoch 0:   3%|▎         | 3/100 [00:01<00:48,  2.00it/s, lr=6e-5, sum_loss=3.890, loss=2.610, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 0:   4%|▍         | 4/100 [00:01<00:40,  2.38it/s, lr=6e-5, sum_loss=3.890, loss=2.610, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 0:   4%|▍         | 4/100 [00:01<00:40,  2.38it/s, lr=5.99e-5, sum_loss=3.780, loss=3.470, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 0:   5%|▌         | 5/100 [00:01<00:35,  2.69it/s, lr=5.99e-5, sum_loss=3.780, loss=3.470, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 0:   5%|▌         | 5/100 [00:01<00:35,  2.69it/s, lr=5.98e-5, sum_loss=3.720, loss=3.550, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:   6%|▌         | 6/100 [00:02<00:31,  2.94it/s, lr=5.98e-5, sum_loss=3.720, loss=3.550, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:   6%|▌         | 6/100 [00:02<00:31,  2.94it/s, lr=5.97e-5, sum_loss=3.610, loss=3.030, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:   7%|▋         | 7/100 [00:02<00:29,  3.15it/s, lr=5.97e-5, sum_loss=3.610, loss=3.030, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:   7%|▋         | 7/100 [00:02<00:29,  3.15it/s, lr=5.96e-5, sum_loss=3.580, loss=3.310, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 0:   8%|▊         | 8/100 [00:02<00:27,  3.33it/s, lr=5.96e-5, sum_loss=3.580, loss=3.310, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 0:   8%|▊         | 8/100 [00:02<00:27,  3.33it/s, lr=5.94e-5, sum_loss=3.470, loss=2.690, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:   9%|▉         | 9/100 [00:02<00:26,  3.47it/s, lr=5.94e-5, sum_loss=3.470, loss=2.690, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:   9%|▉         | 9/100 [00:02<00:26,  3.47it/s, lr=5.92e-5, sum_loss=3.270, loss=1.610, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 0:  10%|█         | 10/100 [00:02<00:24,  3.61it/s, lr=5.92e-5, sum_loss=3.270, loss=1.610, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 0:  10%|█         | 10/100 [00:02<00:24,  3.61it/s, lr=5.9e-5, sum_loss=3.090, loss=1.660, REAL it/s=5.620, Kt/s=2.880] \n",
      "Epoch 0:  11%|█         | 11/100 [00:02<00:23,  3.72it/s, lr=5.9e-5, sum_loss=3.090, loss=1.660, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 0:  11%|█         | 11/100 [00:02<00:23,  3.72it/s, lr=5.88e-5, sum_loss=2.980, loss=1.860, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 0:  12%|█▏        | 12/100 [00:03<00:22,  3.83it/s, lr=5.88e-5, sum_loss=2.980, loss=1.860, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 0:  12%|█▏        | 12/100 [00:03<00:22,  3.83it/s, lr=5.85e-5, sum_loss=2.920, loss=2.310, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  13%|█▎        | 13/100 [00:03<00:22,  3.93it/s, lr=5.85e-5, sum_loss=2.920, loss=2.310, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  13%|█▎        | 13/100 [00:03<00:22,  3.93it/s, lr=5.82e-5, sum_loss=2.840, loss=2.060, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  14%|█▍        | 14/100 [00:03<00:21,  4.02it/s, lr=5.82e-5, sum_loss=2.840, loss=2.060, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  14%|█▍        | 14/100 [00:03<00:21,  4.02it/s, lr=5.79e-5, sum_loss=2.800, loss=2.190, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 0:  15%|█▌        | 15/100 [00:03<00:20,  4.10it/s, lr=5.79e-5, sum_loss=2.800, loss=2.190, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 0:  15%|█▌        | 15/100 [00:03<00:20,  4.10it/s, lr=5.76e-5, sum_loss=2.690, loss=1.070, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 0:  16%|█▌        | 16/100 [00:03<00:20,  4.17it/s, lr=5.76e-5, sum_loss=2.690, loss=1.070, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 0:  16%|█▌        | 16/100 [00:03<00:20,  4.17it/s, lr=5.73e-5, sum_loss=2.610, loss=1.550, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  17%|█▋        | 17/100 [00:04<00:19,  4.23it/s, lr=5.73e-5, sum_loss=2.610, loss=1.550, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  17%|█▋        | 17/100 [00:04<00:19,  4.23it/s, lr=5.69e-5, sum_loss=2.590, loss=2.120, REAL it/s=5.580, Kt/s=2.850]\n",
      "Epoch 0:  18%|█▊        | 18/100 [00:04<00:19,  4.30it/s, lr=5.69e-5, sum_loss=2.590, loss=2.120, REAL it/s=5.580, Kt/s=2.850]\n",
      "Epoch 0:  18%|█▊        | 18/100 [00:04<00:19,  4.30it/s, lr=5.65e-5, sum_loss=2.520, loss=1.240, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 0:  19%|█▉        | 19/100 [00:04<00:18,  4.35it/s, lr=5.65e-5, sum_loss=2.520, loss=1.240, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 0:  19%|█▉        | 19/100 [00:04<00:18,  4.35it/s, lr=5.61e-5, sum_loss=2.450, loss=1.300, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 0:  20%|██        | 20/100 [00:04<00:18,  4.40it/s, lr=5.61e-5, sum_loss=2.450, loss=1.300, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 0:  20%|██        | 20/100 [00:04<00:18,  4.40it/s, lr=5.57e-5, sum_loss=2.410, loss=1.400, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 0:  21%|██        | 21/100 [00:04<00:17,  4.45it/s, lr=5.57e-5, sum_loss=2.410, loss=1.400, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 0:  21%|██        | 21/100 [00:04<00:17,  4.45it/s, lr=5.52e-5, sum_loss=2.330, loss=0.668, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  22%|██▏       | 22/100 [00:04<00:17,  4.49it/s, lr=5.52e-5, sum_loss=2.330, loss=0.668, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  22%|██▏       | 22/100 [00:04<00:17,  4.49it/s, lr=5.48e-5, sum_loss=2.300, loss=1.740, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  23%|██▎       | 23/100 [00:05<00:16,  4.53it/s, lr=5.48e-5, sum_loss=2.300, loss=1.740, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  23%|██▎       | 23/100 [00:05<00:16,  4.53it/s, lr=5.43e-5, sum_loss=2.220, loss=0.379, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  24%|██▍       | 24/100 [00:05<00:16,  4.57it/s, lr=5.43e-5, sum_loss=2.220, loss=0.379, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  24%|██▍       | 24/100 [00:05<00:16,  4.57it/s, lr=5.38e-5, sum_loss=2.200, loss=1.800, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 0:  25%|██▌       | 25/100 [00:05<00:16,  4.61it/s, lr=5.38e-5, sum_loss=2.200, loss=1.800, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 0:  25%|██▌       | 25/100 [00:05<00:16,  4.61it/s, lr=5.32e-5, sum_loss=2.170, loss=1.390, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  26%|██▌       | 26/100 [00:05<00:15,  4.64it/s, lr=5.32e-5, sum_loss=2.170, loss=1.390, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  26%|██▌       | 26/100 [00:05<00:15,  4.64it/s, lr=5.27e-5, sum_loss=2.140, loss=1.230, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  27%|██▋       | 27/100 [00:05<00:15,  4.67it/s, lr=5.27e-5, sum_loss=2.140, loss=1.230, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  27%|██▋       | 27/100 [00:05<00:15,  4.67it/s, lr=5.21e-5, sum_loss=2.090, loss=0.906, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 0:  28%|██▊       | 28/100 [00:05<00:15,  4.70it/s, lr=5.21e-5, sum_loss=2.090, loss=0.906, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 0:  28%|██▊       | 28/100 [00:05<00:15,  4.70it/s, lr=5.15e-5, sum_loss=2.050, loss=0.816, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  29%|██▉       | 29/100 [00:06<00:15,  4.73it/s, lr=5.15e-5, sum_loss=2.050, loss=0.816, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  29%|██▉       | 29/100 [00:06<00:15,  4.73it/s, lr=5.09e-5, sum_loss=2.030, loss=1.450, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  30%|███       | 30/100 [00:06<00:14,  4.75it/s, lr=5.09e-5, sum_loss=2.030, loss=1.450, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  30%|███       | 30/100 [00:06<00:14,  4.75it/s, lr=5.03e-5, sum_loss=1.980, loss=0.602, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 0:  31%|███       | 31/100 [00:06<00:14,  4.77it/s, lr=5.03e-5, sum_loss=1.980, loss=0.602, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 0:  31%|███       | 31/100 [00:06<00:14,  4.77it/s, lr=4.97e-5, sum_loss=1.950, loss=0.926, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:  32%|███▏      | 32/100 [00:06<00:14,  4.79it/s, lr=4.97e-5, sum_loss=1.950, loss=0.926, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 0:  32%|███▏      | 32/100 [00:06<00:14,  4.78it/s, lr=4.91e-5, sum_loss=1.910, loss=0.707, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 0:  33%|███▎      | 33/100 [00:06<00:13,  4.80it/s, lr=4.91e-5, sum_loss=1.910, loss=0.707, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 0:  33%|███▎      | 33/100 [00:06<00:13,  4.80it/s, lr=4.84e-5, sum_loss=1.880, loss=1.120, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  34%|███▍      | 34/100 [00:07<00:13,  4.83it/s, lr=4.84e-5, sum_loss=1.880, loss=1.120, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  34%|███▍      | 34/100 [00:07<00:13,  4.83it/s, lr=4.77e-5, sum_loss=1.840, loss=0.414, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  35%|███▌      | 35/100 [00:07<00:13,  4.84it/s, lr=4.77e-5, sum_loss=1.840, loss=0.414, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  35%|███▌      | 35/100 [00:07<00:13,  4.84it/s, lr=4.7e-5, sum_loss=1.810, loss=1.100, REAL it/s=5.610, Kt/s=2.870] \n",
      "Epoch 0:  36%|███▌      | 36/100 [00:07<00:13,  4.86it/s, lr=4.7e-5, sum_loss=1.810, loss=1.100, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 0:  36%|███▌      | 36/100 [00:07<00:13,  4.86it/s, lr=4.63e-5, sum_loss=1.790, loss=1.190, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  37%|███▋      | 37/100 [00:07<00:12,  4.88it/s, lr=4.63e-5, sum_loss=1.790, loss=1.190, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  37%|███▋      | 37/100 [00:07<00:12,  4.88it/s, lr=4.56e-5, sum_loss=1.800, loss=1.790, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  38%|███▊      | 38/100 [00:07<00:12,  4.90it/s, lr=4.56e-5, sum_loss=1.800, loss=1.790, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 0:  38%|███▊      | 38/100 [00:07<00:12,  4.90it/s, lr=4.49e-5, sum_loss=1.770, loss=1.090, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  39%|███▉      | 39/100 [00:07<00:12,  4.92it/s, lr=4.49e-5, sum_loss=1.770, loss=1.090, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  39%|███▉      | 39/100 [00:07<00:12,  4.92it/s, lr=4.42e-5, sum_loss=1.760, loss=0.844, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 0:  40%|████      | 40/100 [00:08<00:12,  4.93it/s, lr=4.42e-5, sum_loss=1.760, loss=0.844, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 0:  40%|████      | 40/100 [00:08<00:12,  4.93it/s, lr=4.35e-5, sum_loss=1.730, loss=1.000, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 0:  41%|████      | 41/100 [00:08<00:11,  4.95it/s, lr=4.35e-5, sum_loss=1.730, loss=1.000, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 0:  41%|████      | 41/100 [00:08<00:11,  4.95it/s, lr=4.27e-5, sum_loss=1.710, loss=0.605, REAL it/s=5.480, Kt/s=2.800]\n",
      "Epoch 0:  42%|████▏     | 42/100 [00:08<00:11,  4.96it/s, lr=4.27e-5, sum_loss=1.710, loss=0.605, REAL it/s=5.480, Kt/s=2.800]\n",
      "Epoch 0:  42%|████▏     | 42/100 [00:08<00:11,  4.96it/s, lr=4.2e-5, sum_loss=1.700, loss=1.400, REAL it/s=5.370, Kt/s=2.750] \n",
      "Epoch 0:  43%|████▎     | 43/100 [00:08<00:11,  4.97it/s, lr=4.2e-5, sum_loss=1.700, loss=1.400, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 0:  43%|████▎     | 43/100 [00:08<00:11,  4.97it/s, lr=4.12e-5, sum_loss=1.670, loss=0.447, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 0:  44%|████▍     | 44/100 [00:08<00:11,  4.98it/s, lr=4.12e-5, sum_loss=1.670, loss=0.447, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 0:  44%|████▍     | 44/100 [00:08<00:11,  4.98it/s, lr=4.05e-5, sum_loss=1.660, loss=0.887, REAL it/s=5.520, Kt/s=2.820]\n",
      "Epoch 0:  45%|████▌     | 45/100 [00:09<00:11,  4.99it/s, lr=4.05e-5, sum_loss=1.660, loss=0.887, REAL it/s=5.520, Kt/s=2.820]\n",
      "Epoch 0:  45%|████▌     | 45/100 [00:09<00:11,  4.99it/s, lr=3.97e-5, sum_loss=1.660, loss=1.800, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 0:  46%|████▌     | 46/100 [00:09<00:10,  5.00it/s, lr=3.97e-5, sum_loss=1.660, loss=1.800, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 0:  46%|████▌     | 46/100 [00:09<00:10,  5.00it/s, lr=3.89e-5, sum_loss=1.650, loss=1.010, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  47%|████▋     | 47/100 [00:09<00:10,  5.01it/s, lr=3.89e-5, sum_loss=1.650, loss=1.010, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  47%|████▋     | 47/100 [00:09<00:10,  5.01it/s, lr=3.81e-5, sum_loss=1.620, loss=0.490, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  48%|████▊     | 48/100 [00:09<00:10,  5.02it/s, lr=3.81e-5, sum_loss=1.620, loss=0.490, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  48%|████▊     | 48/100 [00:09<00:10,  5.02it/s, lr=3.74e-5, sum_loss=1.600, loss=0.656, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 0:  49%|████▉     | 49/100 [00:09<00:10,  5.03it/s, lr=3.74e-5, sum_loss=1.600, loss=0.656, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 0:  49%|████▉     | 49/100 [00:09<00:10,  5.03it/s, lr=3.66e-5, sum_loss=1.610, loss=2.250, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 0:  50%|█████     | 50/100 [00:09<00:09,  5.04it/s, lr=3.66e-5, sum_loss=1.610, loss=2.250, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 0:  50%|█████     | 50/100 [00:09<00:09,  5.04it/s, lr=3.58e-5, sum_loss=1.600, loss=0.879, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  51%|█████     | 51/100 [00:10<00:09,  5.04it/s, lr=3.58e-5, sum_loss=1.600, loss=0.879, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  51%|█████     | 51/100 [00:10<00:09,  5.04it/s, lr=3.5e-5, sum_loss=1.590, loss=0.770, REAL it/s=5.400, Kt/s=2.760] \n",
      "Epoch 0:  52%|█████▏    | 52/100 [00:10<00:09,  5.05it/s, lr=3.5e-5, sum_loss=1.590, loss=0.770, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 0:  52%|█████▏    | 52/100 [00:10<00:09,  5.05it/s, lr=3.42e-5, sum_loss=1.570, loss=0.283, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 0:  53%|█████▎    | 53/100 [00:10<00:09,  5.06it/s, lr=3.42e-5, sum_loss=1.570, loss=0.283, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 0:  53%|█████▎    | 53/100 [00:10<00:09,  5.06it/s, lr=3.34e-5, sum_loss=1.550, loss=0.703, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 0:  54%|█████▍    | 54/100 [00:10<00:09,  5.06it/s, lr=3.34e-5, sum_loss=1.550, loss=0.703, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 0:  54%|█████▍    | 54/100 [00:10<00:09,  5.06it/s, lr=3.26e-5, sum_loss=1.530, loss=0.746, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  55%|█████▌    | 55/100 [00:10<00:08,  5.07it/s, lr=3.26e-5, sum_loss=1.530, loss=0.746, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  55%|█████▌    | 55/100 [00:10<00:08,  5.07it/s, lr=3.19e-5, sum_loss=1.510, loss=0.609, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 0:  56%|█████▌    | 56/100 [00:11<00:08,  5.08it/s, lr=3.19e-5, sum_loss=1.510, loss=0.609, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 0:  56%|█████▌    | 56/100 [00:11<00:08,  5.08it/s, lr=3.11e-5, sum_loss=1.510, loss=1.590, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 0:  57%|█████▋    | 57/100 [00:11<00:08,  5.09it/s, lr=3.11e-5, sum_loss=1.510, loss=1.590, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 0:  57%|█████▋    | 57/100 [00:11<00:08,  5.09it/s, lr=3.03e-5, sum_loss=1.490, loss=0.432, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  58%|█████▊    | 58/100 [00:11<00:08,  5.10it/s, lr=3.03e-5, sum_loss=1.490, loss=0.432, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  58%|█████▊    | 58/100 [00:11<00:08,  5.10it/s, lr=2.95e-5, sum_loss=1.480, loss=0.432, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  59%|█████▉    | 59/100 [00:11<00:08,  5.11it/s, lr=2.95e-5, sum_loss=1.480, loss=0.432, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 0:  59%|█████▉    | 59/100 [00:11<00:08,  5.11it/s, lr=2.88e-5, sum_loss=1.450, loss=0.119, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  60%|██████    | 60/100 [00:11<00:07,  5.12it/s, lr=2.88e-5, sum_loss=1.450, loss=0.119, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  60%|██████    | 60/100 [00:11<00:07,  5.12it/s, lr=2.8e-5, sum_loss=1.430, loss=0.691, REAL it/s=5.540, Kt/s=2.840] \n",
      "Epoch 0:  61%|██████    | 61/100 [00:11<00:07,  5.12it/s, lr=2.8e-5, sum_loss=1.430, loss=0.691, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 0:  61%|██████    | 61/100 [00:11<00:07,  5.12it/s, lr=2.73e-5, sum_loss=1.420, loss=0.719, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  62%|██████▏   | 62/100 [00:12<00:07,  5.13it/s, lr=2.73e-5, sum_loss=1.420, loss=0.719, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  62%|██████▏   | 62/100 [00:12<00:07,  5.13it/s, lr=2.65e-5, sum_loss=1.410, loss=0.625, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  63%|██████▎   | 63/100 [00:12<00:07,  5.13it/s, lr=2.65e-5, sum_loss=1.410, loss=0.625, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  63%|██████▎   | 63/100 [00:12<00:07,  5.13it/s, lr=2.58e-5, sum_loss=1.410, loss=1.490, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  64%|██████▍   | 64/100 [00:12<00:07,  5.14it/s, lr=2.58e-5, sum_loss=1.410, loss=1.490, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  64%|██████▍   | 64/100 [00:12<00:07,  5.14it/s, lr=2.51e-5, sum_loss=1.410, loss=1.410, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 0:  65%|██████▌   | 65/100 [00:12<00:06,  5.15it/s, lr=2.51e-5, sum_loss=1.410, loss=1.410, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 0:  65%|██████▌   | 65/100 [00:12<00:06,  5.15it/s, lr=2.44e-5, sum_loss=1.400, loss=0.766, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 0:  66%|██████▌   | 66/100 [00:12<00:06,  5.15it/s, lr=2.44e-5, sum_loss=1.400, loss=0.766, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 0:  66%|██████▌   | 66/100 [00:12<00:06,  5.15it/s, lr=2.37e-5, sum_loss=1.380, loss=0.404, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 0:  67%|██████▋   | 67/100 [00:12<00:06,  5.16it/s, lr=2.37e-5, sum_loss=1.380, loss=0.404, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 0:  67%|██████▋   | 67/100 [00:12<00:06,  5.16it/s, lr=2.3e-5, sum_loss=1.380, loss=0.730, REAL it/s=5.570, Kt/s=2.850] \n",
      "Epoch 0:  68%|██████▊   | 68/100 [00:13<00:06,  5.16it/s, lr=2.3e-5, sum_loss=1.380, loss=0.730, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 0:  68%|██████▊   | 68/100 [00:13<00:06,  5.16it/s, lr=2.23e-5, sum_loss=1.360, loss=0.482, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 0:  69%|██████▉   | 69/100 [00:13<00:05,  5.17it/s, lr=2.23e-5, sum_loss=1.360, loss=0.482, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 0:  69%|██████▉   | 69/100 [00:13<00:05,  5.17it/s, lr=2.16e-5, sum_loss=1.350, loss=0.656, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  70%|███████   | 70/100 [00:13<00:05,  5.17it/s, lr=2.16e-5, sum_loss=1.350, loss=0.656, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 0:  70%|███████   | 70/100 [00:13<00:05,  5.17it/s, lr=2.09e-5, sum_loss=1.350, loss=1.390, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 0:  71%|███████   | 71/100 [00:13<00:05,  5.17it/s, lr=2.09e-5, sum_loss=1.350, loss=1.390, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 0:  71%|███████   | 71/100 [00:13<00:05,  5.17it/s, lr=2.03e-5, sum_loss=1.370, loss=2.300, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 0:  72%|███████▏  | 72/100 [00:13<00:05,  5.18it/s, lr=2.03e-5, sum_loss=1.370, loss=2.300, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 0:  72%|███████▏  | 72/100 [00:13<00:05,  5.18it/s, lr=1.97e-5, sum_loss=1.370, loss=1.370, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 0:  73%|███████▎  | 73/100 [00:14<00:05,  5.18it/s, lr=1.97e-5, sum_loss=1.370, loss=1.370, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 0:  73%|███████▎  | 73/100 [00:14<00:05,  5.18it/s, lr=1.91e-5, sum_loss=1.370, loss=1.290, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 0:  74%|███████▍  | 74/100 [00:14<00:05,  5.18it/s, lr=1.91e-5, sum_loss=1.370, loss=1.290, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 0:  74%|███████▍  | 74/100 [00:14<00:05,  5.18it/s, lr=1.85e-5, sum_loss=1.370, loss=1.180, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  75%|███████▌  | 75/100 [00:14<00:04,  5.19it/s, lr=1.85e-5, sum_loss=1.370, loss=1.180, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  75%|███████▌  | 75/100 [00:14<00:04,  5.19it/s, lr=1.79e-5, sum_loss=1.380, loss=2.160, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 0:  76%|███████▌  | 76/100 [00:14<00:04,  5.19it/s, lr=1.79e-5, sum_loss=1.380, loss=2.160, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 0:  76%|███████▌  | 76/100 [00:14<00:04,  5.19it/s, lr=1.73e-5, sum_loss=1.360, loss=0.477, REAL it/s=5.600, Kt/s=2.860]\n",
      "Epoch 0:  77%|███████▋  | 77/100 [00:14<00:04,  5.20it/s, lr=1.73e-5, sum_loss=1.360, loss=0.477, REAL it/s=5.600, Kt/s=2.860]\n",
      "Epoch 0:  77%|███████▋  | 77/100 [00:14<00:04,  5.20it/s, lr=1.68e-5, sum_loss=1.360, loss=1.120, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 0:  78%|███████▊  | 78/100 [00:14<00:04,  5.20it/s, lr=1.68e-5, sum_loss=1.360, loss=1.120, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 0:  78%|███████▊  | 78/100 [00:14<00:04,  5.20it/s, lr=1.62e-5, sum_loss=1.350, loss=1.080, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 0:  79%|███████▉  | 79/100 [00:15<00:04,  5.21it/s, lr=1.62e-5, sum_loss=1.350, loss=1.080, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 0:  79%|███████▉  | 79/100 [00:15<00:04,  5.21it/s, lr=1.57e-5, sum_loss=1.340, loss=0.479, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  80%|████████  | 80/100 [00:15<00:03,  5.22it/s, lr=1.57e-5, sum_loss=1.340, loss=0.479, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 0:  80%|████████  | 80/100 [00:15<00:03,  5.22it/s, lr=1.52e-5, sum_loss=1.330, loss=0.387, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 0:  81%|████████  | 81/100 [00:15<00:03,  5.22it/s, lr=1.52e-5, sum_loss=1.330, loss=0.387, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 0:  81%|████████  | 81/100 [00:15<00:03,  5.22it/s, lr=1.48e-5, sum_loss=1.320, loss=0.414, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 0:  82%|████████▏ | 82/100 [00:15<00:03,  5.22it/s, lr=1.48e-5, sum_loss=1.320, loss=0.414, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 0:  82%|████████▏ | 82/100 [00:15<00:03,  5.22it/s, lr=1.43e-5, sum_loss=1.310, loss=0.320, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 0:  83%|████████▎ | 83/100 [00:15<00:03,  5.22it/s, lr=1.43e-5, sum_loss=1.310, loss=0.320, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 0:  83%|████████▎ | 83/100 [00:15<00:03,  5.22it/s, lr=1.39e-5, sum_loss=1.300, loss=0.453, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  84%|████████▍ | 84/100 [00:16<00:03,  5.23it/s, lr=1.39e-5, sum_loss=1.300, loss=0.453, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  84%|████████▍ | 84/100 [00:16<00:03,  5.23it/s, lr=1.35e-5, sum_loss=1.300, loss=1.560, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 0:  85%|████████▌ | 85/100 [00:16<00:02,  5.23it/s, lr=1.35e-5, sum_loss=1.300, loss=1.560, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 0:  85%|████████▌ | 85/100 [00:16<00:02,  5.23it/s, lr=1.31e-5, sum_loss=1.300, loss=0.312, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  86%|████████▌ | 86/100 [00:16<00:02,  5.24it/s, lr=1.31e-5, sum_loss=1.300, loss=0.312, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  86%|████████▌ | 86/100 [00:16<00:02,  5.24it/s, lr=1.27e-5, sum_loss=1.290, loss=1.020, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  87%|████████▋ | 87/100 [00:16<00:02,  5.24it/s, lr=1.27e-5, sum_loss=1.290, loss=1.020, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  87%|████████▋ | 87/100 [00:16<00:02,  5.24it/s, lr=1.24e-5, sum_loss=1.280, loss=0.578, REAL it/s=5.520, Kt/s=2.820]\n",
      "Epoch 0:  88%|████████▊ | 88/100 [00:16<00:02,  5.24it/s, lr=1.24e-5, sum_loss=1.280, loss=0.578, REAL it/s=5.520, Kt/s=2.820]\n",
      "Epoch 0:  88%|████████▊ | 88/100 [00:16<00:02,  5.24it/s, lr=1.21e-5, sum_loss=1.270, loss=0.684, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 0:  89%|████████▉ | 89/100 [00:16<00:02,  5.24it/s, lr=1.21e-5, sum_loss=1.270, loss=0.684, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 0:  89%|████████▉ | 89/100 [00:16<00:02,  5.24it/s, lr=1.18e-5, sum_loss=1.270, loss=0.309, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 0:  90%|█████████ | 90/100 [00:17<00:01,  5.24it/s, lr=1.18e-5, sum_loss=1.270, loss=0.309, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 0:  90%|█████████ | 90/100 [00:17<00:01,  5.24it/s, lr=1.15e-5, sum_loss=1.260, loss=0.375, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 0:  91%|█████████ | 91/100 [00:17<00:01,  5.24it/s, lr=1.15e-5, sum_loss=1.260, loss=0.375, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 0:  91%|█████████ | 91/100 [00:17<00:01,  5.24it/s, lr=1.12e-5, sum_loss=1.250, loss=0.340, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 0:  92%|█████████▏| 92/100 [00:17<00:01,  5.25it/s, lr=1.12e-5, sum_loss=1.250, loss=0.340, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 0:  92%|█████████▏| 92/100 [00:17<00:01,  5.25it/s, lr=1.1e-5, sum_loss=1.230, loss=0.239, REAL it/s=5.340, Kt/s=2.730] \n",
      "Epoch 0:  93%|█████████▎| 93/100 [00:17<00:01,  5.25it/s, lr=1.1e-5, sum_loss=1.230, loss=0.239, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 0:  93%|█████████▎| 93/100 [00:17<00:01,  5.25it/s, lr=1.08e-5, sum_loss=1.230, loss=1.600, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 0:  94%|█████████▍| 94/100 [00:17<00:01,  5.25it/s, lr=1.08e-5, sum_loss=1.230, loss=1.600, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 0:  94%|█████████▍| 94/100 [00:17<00:01,  5.25it/s, lr=1.06e-5, sum_loss=1.230, loss=1.020, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  95%|█████████▌| 95/100 [00:18<00:00,  5.25it/s, lr=1.06e-5, sum_loss=1.230, loss=1.020, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 0:  95%|█████████▌| 95/100 [00:18<00:00,  5.25it/s, lr=1.04e-5, sum_loss=1.230, loss=0.379, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 0:  96%|█████████▌| 96/100 [00:18<00:00,  5.26it/s, lr=1.04e-5, sum_loss=1.230, loss=0.379, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 0:  96%|█████████▌| 96/100 [00:18<00:00,  5.26it/s, lr=1.03e-5, sum_loss=1.230, loss=0.852, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 0:  97%|█████████▋| 97/100 [00:18<00:00,  5.26it/s, lr=1.03e-5, sum_loss=1.230, loss=0.852, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 0:  97%|█████████▋| 97/100 [00:18<00:00,  5.26it/s, lr=1.02e-5, sum_loss=1.210, loss=0.147, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 0:  98%|█████████▊| 98/100 [00:18<00:00,  5.26it/s, lr=1.02e-5, sum_loss=1.210, loss=0.147, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 0:  98%|█████████▊| 98/100 [00:18<00:00,  5.26it/s, lr=1.01e-5, sum_loss=1.200, loss=0.531, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  99%|█████████▉| 99/100 [00:18<00:00,  5.27it/s, lr=1.01e-5, sum_loss=1.200, loss=0.531, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 0:  99%|█████████▉| 99/100 [00:18<00:00,  5.27it/s, lr=1e-5, sum_loss=1.200, loss=0.126, REAL it/s=5.770, Kt/s=2.950]   \n",
      "Epoch 0: 100%|██████████| 100/100 [00:18<00:00,  5.27it/s, lr=1e-5, sum_loss=1.200, loss=0.126, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 0: 100%|██████████| 100/100 [00:18<00:00,  5.27it/s, lr=1e-5, sum_loss=1.180, loss=0.125, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 0: 100%|██████████| 100/100 [00:19<00:00,  5.26it/s, lr=1e-5, sum_loss=1.180, loss=0.125, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=1.180, loss=0.125, REAL it/s=5.610, Kt/s=2.870]          \n",
      "Epoch 1:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=1.180, loss=0.125, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:   1%|          | 1/100 [00:00<00:42,  2.34it/s, lr=1e-5, sum_loss=1.180, loss=0.125, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:   1%|          | 1/100 [00:00<00:42,  2.34it/s, lr=1e-5, sum_loss=1.220, loss=1.220, REAL it/s=2.060, Kt/s=1.050]\n",
      "Epoch 1:   2%|▏         | 2/100 [00:00<00:29,  3.33it/s, lr=1e-5, sum_loss=1.220, loss=1.220, REAL it/s=2.060, Kt/s=1.050]\n",
      "Epoch 1:   2%|▏         | 2/100 [00:00<00:29,  3.33it/s, lr=1e-5, sum_loss=0.680, loss=0.137, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 1:   3%|▎         | 3/100 [00:00<00:25,  3.86it/s, lr=1e-5, sum_loss=0.680, loss=0.137, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 1:   3%|▎         | 3/100 [00:00<00:25,  3.86it/s, lr=1e-5, sum_loss=1.050, loss=1.810, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 1:   4%|▍         | 4/100 [00:00<00:22,  4.19it/s, lr=1e-5, sum_loss=1.050, loss=1.810, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 1:   4%|▍         | 4/100 [00:00<00:22,  4.19it/s, lr=1e-5, sum_loss=0.969, loss=0.707, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 1:   5%|▌         | 5/100 [00:01<00:21,  4.41it/s, lr=1e-5, sum_loss=0.969, loss=0.707, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 1:   5%|▌         | 5/100 [00:01<00:21,  4.41it/s, lr=1e-5, sum_loss=0.824, loss=0.249, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:   6%|▌         | 6/100 [00:01<00:20,  4.57it/s, lr=1e-5, sum_loss=0.824, loss=0.249, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:   6%|▌         | 6/100 [00:01<00:20,  4.57it/s, lr=1e-5, sum_loss=0.809, loss=0.711, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 1:   7%|▋         | 7/100 [00:01<00:19,  4.68it/s, lr=1e-5, sum_loss=0.809, loss=0.711, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 1:   7%|▋         | 7/100 [00:01<00:19,  4.68it/s, lr=1e-5, sum_loss=0.707, loss=0.0952, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:   8%|▊         | 8/100 [00:01<00:19,  4.76it/s, lr=1e-5, sum_loss=0.707, loss=0.0952, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:   8%|▊         | 8/100 [00:01<00:19,  4.76it/s, lr=1e-5, sum_loss=0.641, loss=0.195, REAL it/s=5.420, Kt/s=2.770] \n",
      "Epoch 1:   9%|▉         | 9/100 [00:01<00:18,  4.83it/s, lr=1e-5, sum_loss=0.641, loss=0.195, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 1:   9%|▉         | 9/100 [00:01<00:18,  4.83it/s, lr=1e-5, sum_loss=0.590, loss=0.190, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 1:  10%|█         | 10/100 [00:02<00:18,  4.88it/s, lr=1e-5, sum_loss=0.590, loss=0.190, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 1:  10%|█         | 10/100 [00:02<00:18,  4.88it/s, lr=1e-5, sum_loss=0.547, loss=0.151, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  11%|█         | 11/100 [00:02<00:18,  4.94it/s, lr=1e-5, sum_loss=0.547, loss=0.151, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  11%|█         | 11/100 [00:02<00:18,  4.94it/s, lr=1e-5, sum_loss=0.574, loss=0.840, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  12%|█▏        | 12/100 [00:02<00:17,  4.98it/s, lr=1e-5, sum_loss=0.574, loss=0.840, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  12%|█▏        | 12/100 [00:02<00:17,  4.98it/s, lr=1e-5, sum_loss=0.691, loss=2.020, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  13%|█▎        | 13/100 [00:02<00:17,  5.02it/s, lr=1e-5, sum_loss=0.691, loss=2.020, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  13%|█▎        | 13/100 [00:02<00:17,  5.02it/s, lr=1e-5, sum_loss=0.664, loss=0.324, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  14%|█▍        | 14/100 [00:02<00:17,  5.05it/s, lr=1e-5, sum_loss=0.664, loss=0.324, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  14%|█▍        | 14/100 [00:02<00:17,  5.05it/s, lr=1e-5, sum_loss=0.637, loss=0.307, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  15%|█▌        | 15/100 [00:02<00:16,  5.08it/s, lr=1e-5, sum_loss=0.637, loss=0.307, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  15%|█▌        | 15/100 [00:02<00:16,  5.08it/s, lr=1e-5, sum_loss=0.605, loss=0.120, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  16%|█▌        | 16/100 [00:03<00:16,  5.11it/s, lr=1e-5, sum_loss=0.605, loss=0.120, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  16%|█▌        | 16/100 [00:03<00:16,  5.11it/s, lr=1e-5, sum_loss=0.645, loss=1.260, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  17%|█▋        | 17/100 [00:03<00:16,  5.13it/s, lr=1e-5, sum_loss=0.645, loss=1.260, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  17%|█▋        | 17/100 [00:03<00:16,  5.13it/s, lr=1e-5, sum_loss=0.629, loss=0.355, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  18%|█▊        | 18/100 [00:03<00:15,  5.15it/s, lr=1e-5, sum_loss=0.629, loss=0.355, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  18%|█▊        | 18/100 [00:03<00:15,  5.15it/s, lr=1e-5, sum_loss=0.637, loss=0.773, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 1:  19%|█▉        | 19/100 [00:03<00:15,  5.16it/s, lr=1e-5, sum_loss=0.637, loss=0.773, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 1:  19%|█▉        | 19/100 [00:03<00:15,  5.16it/s, lr=1e-5, sum_loss=0.605, loss=0.0801, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 1:  20%|██        | 20/100 [00:03<00:15,  5.17it/s, lr=1e-5, sum_loss=0.605, loss=0.0801, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 1:  20%|██        | 20/100 [00:03<00:15,  5.17it/s, lr=1e-5, sum_loss=0.578, loss=0.0752, REAL it/s=5.220, Kt/s=2.670]\n",
      "Epoch 1:  21%|██        | 21/100 [00:04<00:15,  5.18it/s, lr=1e-5, sum_loss=0.578, loss=0.0752, REAL it/s=5.220, Kt/s=2.670]\n",
      "Epoch 1:  21%|██        | 21/100 [00:04<00:15,  5.18it/s, lr=1e-5, sum_loss=0.598, loss=1.020, REAL it/s=5.380, Kt/s=2.760] \n",
      "Epoch 1:  22%|██▏       | 22/100 [00:04<00:15,  5.18it/s, lr=1e-5, sum_loss=0.598, loss=1.020, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 1:  22%|██▏       | 22/100 [00:04<00:15,  5.18it/s, lr=1e-5, sum_loss=0.578, loss=0.203, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 1:  23%|██▎       | 23/100 [00:04<00:14,  5.20it/s, lr=1e-5, sum_loss=0.578, loss=0.203, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 1:  23%|██▎       | 23/100 [00:04<00:14,  5.20it/s, lr=1e-5, sum_loss=0.559, loss=0.0522, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  24%|██▍       | 24/100 [00:04<00:14,  5.21it/s, lr=1e-5, sum_loss=0.559, loss=0.0522, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  24%|██▍       | 24/100 [00:04<00:14,  5.21it/s, lr=1e-5, sum_loss=0.535, loss=0.0703, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  25%|██▌       | 25/100 [00:04<00:14,  5.22it/s, lr=1e-5, sum_loss=0.535, loss=0.0703, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  25%|██▌       | 25/100 [00:04<00:14,  5.22it/s, lr=1e-5, sum_loss=0.531, loss=0.441, REAL it/s=5.440, Kt/s=2.790] \n",
      "Epoch 1:  26%|██▌       | 26/100 [00:04<00:14,  5.23it/s, lr=1e-5, sum_loss=0.531, loss=0.441, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 1:  26%|██▌       | 26/100 [00:04<00:14,  5.23it/s, lr=1e-5, sum_loss=0.586, loss=1.910, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  27%|██▋       | 27/100 [00:05<00:13,  5.24it/s, lr=1e-5, sum_loss=0.586, loss=1.910, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 1:  27%|██▋       | 27/100 [00:05<00:13,  5.24it/s, lr=1e-5, sum_loss=0.566, loss=0.0771, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 1:  28%|██▊       | 28/100 [00:05<00:13,  5.25it/s, lr=1e-5, sum_loss=0.566, loss=0.0771, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 1:  28%|██▊       | 28/100 [00:05<00:13,  5.25it/s, lr=1e-5, sum_loss=0.551, loss=0.146, REAL it/s=5.450, Kt/s=2.790] \n",
      "Epoch 1:  29%|██▉       | 29/100 [00:05<00:13,  5.26it/s, lr=1e-5, sum_loss=0.551, loss=0.146, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  29%|██▉       | 29/100 [00:05<00:13,  5.26it/s, lr=1e-5, sum_loss=0.535, loss=0.0679, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  30%|███       | 30/100 [00:05<00:13,  5.26it/s, lr=1e-5, sum_loss=0.535, loss=0.0679, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  30%|███       | 30/100 [00:05<00:13,  5.26it/s, lr=1e-5, sum_loss=0.551, loss=0.980, REAL it/s=5.370, Kt/s=2.750] \n",
      "Epoch 1:  31%|███       | 31/100 [00:05<00:13,  5.27it/s, lr=1e-5, sum_loss=0.551, loss=0.980, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 1:  31%|███       | 31/100 [00:05<00:13,  5.27it/s, lr=1e-5, sum_loss=0.531, loss=0.0344, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  32%|███▏      | 32/100 [00:06<00:12,  5.28it/s, lr=1e-5, sum_loss=0.531, loss=0.0344, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  32%|███▏      | 32/100 [00:06<00:12,  5.28it/s, lr=1e-5, sum_loss=0.578, loss=1.980, REAL it/s=5.580, Kt/s=2.860] \n",
      "Epoch 1:  33%|███▎      | 33/100 [00:06<00:12,  5.29it/s, lr=1e-5, sum_loss=0.578, loss=1.980, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  33%|███▎      | 33/100 [00:06<00:12,  5.29it/s, lr=1e-5, sum_loss=0.566, loss=0.273, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:  34%|███▍      | 34/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.566, loss=0.273, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:  34%|███▍      | 34/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.582, loss=0.992, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 1:  35%|███▌      | 35/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.582, loss=0.992, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 1:  35%|███▌      | 35/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.566, loss=0.153, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  36%|███▌      | 36/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.566, loss=0.153, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  36%|███▌      | 36/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.578, loss=0.914, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  37%|███▋      | 37/100 [00:06<00:11,  5.32it/s, lr=1e-5, sum_loss=0.578, loss=0.914, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  37%|███▋      | 37/100 [00:06<00:11,  5.32it/s, lr=1e-5, sum_loss=0.566, loss=0.312, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 1:  38%|███▊      | 38/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.566, loss=0.312, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 1:  38%|███▊      | 38/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.562, loss=0.414, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  39%|███▉      | 39/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.562, loss=0.414, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  39%|███▉      | 39/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.551, loss=0.105, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  40%|████      | 40/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.551, loss=0.105, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  40%|████      | 40/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.539, loss=0.179, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  41%|████      | 41/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.539, loss=0.179, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  41%|████      | 41/100 [00:07<00:11,  5.33it/s, lr=1e-5, sum_loss=0.570, loss=1.730, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  42%|████▏     | 42/100 [00:07<00:10,  5.34it/s, lr=1e-5, sum_loss=0.570, loss=1.730, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  42%|████▏     | 42/100 [00:07<00:10,  5.34it/s, lr=1e-5, sum_loss=0.566, loss=0.416, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  43%|████▎     | 43/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.566, loss=0.416, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  43%|████▎     | 43/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.555, loss=0.187, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:  44%|████▍     | 44/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.555, loss=0.187, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 1:  44%|████▍     | 44/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.547, loss=0.247, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  45%|████▌     | 45/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.547, loss=0.247, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  45%|████▌     | 45/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.543, loss=0.287, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  46%|████▌     | 46/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.543, loss=0.287, REAL it/s=5.460, Kt/s=2.790]\n",
      "Epoch 1:  46%|████▌     | 46/100 [00:08<00:10,  5.35it/s, lr=1e-5, sum_loss=0.531, loss=0.115, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 1:  47%|████▋     | 47/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.531, loss=0.115, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 1:  47%|████▋     | 47/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.523, loss=0.154, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 1:  48%|████▊     | 48/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.523, loss=0.154, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 1:  48%|████▊     | 48/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.520, loss=0.320, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 1:  49%|████▉     | 49/100 [00:09<00:09,  5.35it/s, lr=1e-5, sum_loss=0.520, loss=0.320, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 1:  49%|████▉     | 49/100 [00:09<00:09,  5.35it/s, lr=1e-5, sum_loss=0.512, loss=0.159, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 1:  50%|█████     | 50/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.512, loss=0.159, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 1:  50%|█████     | 50/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.504, loss=0.0996, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 1:  51%|█████     | 51/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.504, loss=0.0996, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 1:  51%|█████     | 51/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.498, loss=0.161, REAL it/s=5.540, Kt/s=2.840] \n",
      "Epoch 1:  52%|█████▏    | 52/100 [00:09<00:08,  5.36it/s, lr=1e-5, sum_loss=0.498, loss=0.161, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  52%|█████▏    | 52/100 [00:09<00:08,  5.36it/s, lr=1e-5, sum_loss=0.492, loss=0.258, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 1:  53%|█████▎    | 53/100 [00:09<00:08,  5.36it/s, lr=1e-5, sum_loss=0.492, loss=0.258, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 1:  53%|█████▎    | 53/100 [00:09<00:08,  5.36it/s, lr=1e-5, sum_loss=0.504, loss=1.050, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  54%|█████▍    | 54/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.504, loss=1.050, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  54%|█████▍    | 54/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.496, loss=0.0771, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  55%|█████▌    | 55/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.496, loss=0.0771, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  55%|█████▌    | 55/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.504, loss=0.945, REAL it/s=5.400, Kt/s=2.760] \n",
      "Epoch 1:  56%|█████▌    | 56/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.504, loss=0.945, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 1:  56%|█████▌    | 56/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.512, loss=0.895, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  57%|█████▋    | 57/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.512, loss=0.895, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 1:  57%|█████▋    | 57/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.508, loss=0.218, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 1:  58%|█████▊    | 58/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.508, loss=0.218, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 1:  58%|█████▊    | 58/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.516, loss=0.973, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 1:  59%|█████▉    | 59/100 [00:10<00:07,  5.38it/s, lr=1e-5, sum_loss=0.516, loss=0.973, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 1:  59%|█████▉    | 59/100 [00:10<00:07,  5.38it/s, lr=1e-5, sum_loss=0.535, loss=1.790, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 1:  60%|██████    | 60/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.535, loss=1.790, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 1:  60%|██████    | 60/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.551, loss=1.310, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 1:  61%|██████    | 61/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.551, loss=1.310, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 1:  61%|██████    | 61/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.969, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  62%|██████▏   | 62/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.969, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  62%|██████▏   | 62/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.699, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  63%|██████▎   | 63/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.699, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  63%|██████▎   | 63/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.551, loss=0.114, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 1:  64%|██████▍   | 64/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.551, loss=0.114, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 1:  64%|██████▍   | 64/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.547, loss=0.352, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 1:  65%|██████▌   | 65/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.547, loss=0.352, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 1:  65%|██████▌   | 65/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.543, loss=0.147, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 1:  66%|██████▌   | 66/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.543, loss=0.147, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 1:  66%|██████▌   | 66/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.539, loss=0.299, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 1:  67%|██████▋   | 67/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.539, loss=0.299, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 1:  67%|██████▋   | 67/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=1.980, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 1:  68%|██████▊   | 68/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=1.980, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 1:  68%|██████▊   | 68/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.459, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 1:  69%|██████▉   | 69/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.559, loss=0.459, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 1:  69%|██████▉   | 69/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.555, loss=0.138, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  70%|███████   | 70/100 [00:12<00:05,  5.39it/s, lr=1e-5, sum_loss=0.555, loss=0.138, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  70%|███████   | 70/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.551, loss=0.297, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  71%|███████   | 71/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.551, loss=0.297, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  71%|███████   | 71/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.547, loss=0.142, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 1:  72%|███████▏  | 72/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.547, loss=0.142, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 1:  72%|███████▏  | 72/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.547, loss=0.414, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  73%|███████▎  | 73/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.547, loss=0.414, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  73%|███████▎  | 73/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.543, loss=0.160, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 1:  74%|███████▍  | 74/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.543, loss=0.160, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 1:  74%|███████▍  | 74/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.535, loss=0.0928, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 1:  75%|███████▌  | 75/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.535, loss=0.0928, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 1:  75%|███████▌  | 75/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.535, loss=0.707, REAL it/s=5.420, Kt/s=2.780] \n",
      "Epoch 1:  76%|███████▌  | 76/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.535, loss=0.707, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 1:  76%|███████▌  | 76/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.531, loss=0.262, REAL it/s=5.270, Kt/s=2.700]\n",
      "Epoch 1:  77%|███████▋  | 77/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.531, loss=0.262, REAL it/s=5.270, Kt/s=2.700]\n",
      "Epoch 1:  77%|███████▋  | 77/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.527, loss=0.158, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.527, loss=0.158, REAL it/s=5.310, Kt/s=2.720]\n",
      "Epoch 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.527, loss=0.178, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  79%|███████▉  | 79/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.527, loss=0.178, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  79%|███████▉  | 79/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.527, loss=0.727, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 1:  80%|████████  | 80/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.527, loss=0.727, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 1:  80%|████████  | 80/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.539, loss=1.190, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 1:  81%|████████  | 81/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.539, loss=1.190, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 1:  81%|████████  | 81/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.547, loss=1.310, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  82%|████████▏ | 82/100 [00:15<00:03,  5.40it/s, lr=1e-5, sum_loss=0.547, loss=1.310, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 1:  82%|████████▏ | 82/100 [00:15<00:03,  5.40it/s, lr=1e-5, sum_loss=0.551, loss=1.110, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  83%|████████▎ | 83/100 [00:15<00:03,  5.41it/s, lr=1e-5, sum_loss=0.551, loss=1.110, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  83%|████████▎ | 83/100 [00:15<00:03,  5.41it/s, lr=1e-5, sum_loss=0.547, loss=0.120, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  84%|████████▍ | 84/100 [00:15<00:02,  5.40it/s, lr=1e-5, sum_loss=0.547, loss=0.120, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  84%|████████▍ | 84/100 [00:15<00:02,  5.40it/s, lr=1e-5, sum_loss=0.539, loss=0.102, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  85%|████████▌ | 85/100 [00:15<00:02,  5.40it/s, lr=1e-5, sum_loss=0.539, loss=0.102, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 1:  85%|████████▌ | 85/100 [00:15<00:02,  5.40it/s, lr=1e-5, sum_loss=0.551, loss=1.470, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  86%|████████▌ | 86/100 [00:15<00:02,  5.41it/s, lr=1e-5, sum_loss=0.551, loss=1.470, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  86%|████████▌ | 86/100 [00:15<00:02,  5.41it/s, lr=1e-5, sum_loss=0.543, loss=0.0889, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  87%|████████▋ | 87/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.543, loss=0.0889, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 1:  87%|████████▋ | 87/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.539, loss=0.230, REAL it/s=5.590, Kt/s=2.860] \n",
      "Epoch 1:  88%|████████▊ | 88/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.539, loss=0.230, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 1:  88%|████████▊ | 88/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.535, loss=0.107, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 1:  89%|████████▉ | 89/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.535, loss=0.107, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 1:  89%|████████▉ | 89/100 [00:16<00:02,  5.41it/s, lr=1e-5, sum_loss=0.535, loss=0.734, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 1:  90%|█████████ | 90/100 [00:16<00:01,  5.41it/s, lr=1e-5, sum_loss=0.535, loss=0.734, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 1:  90%|█████████ | 90/100 [00:16<00:01,  5.41it/s, lr=1e-5, sum_loss=0.531, loss=0.111, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 1:  91%|█████████ | 91/100 [00:16<00:01,  5.41it/s, lr=1e-5, sum_loss=0.531, loss=0.111, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 1:  91%|█████████ | 91/100 [00:16<00:01,  5.41it/s, lr=1e-5, sum_loss=0.531, loss=0.420, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 1:  92%|█████████▏| 92/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.531, loss=0.420, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 1:  92%|█████████▏| 92/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.527, loss=0.157, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 1:  93%|█████████▎| 93/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.527, loss=0.157, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 1:  93%|█████████▎| 93/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.523, loss=0.266, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  94%|█████████▍| 94/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.523, loss=0.266, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 1:  94%|█████████▍| 94/100 [00:17<00:01,  5.41it/s, lr=1e-5, sum_loss=0.523, loss=0.590, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  95%|█████████▌| 95/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.523, loss=0.590, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 1:  95%|█████████▌| 95/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.527, loss=0.742, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  96%|█████████▌| 96/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.527, loss=0.742, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 1:  96%|█████████▌| 96/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.520, loss=0.0713, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 1:  97%|█████████▋| 97/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.520, loss=0.0713, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 1:  97%|█████████▋| 97/100 [00:17<00:00,  5.41it/s, lr=1e-5, sum_loss=0.516, loss=0.0718, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  98%|█████████▊| 98/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.516, loss=0.0718, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 1:  98%|█████████▊| 98/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.527, loss=1.550, REAL it/s=5.570, Kt/s=2.850] \n",
      "Epoch 1:  99%|█████████▉| 99/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.527, loss=1.550, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 1:  99%|█████████▉| 99/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.520, loss=0.0708, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 1: 100%|██████████| 100/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.520, loss=0.0708, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 1: 100%|██████████| 100/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.516, loss=0.176, REAL it/s=5.470, Kt/s=2.800] \n",
      "Epoch 1: 100%|██████████| 100/100 [00:18<00:00,  5.42it/s, lr=1e-5, sum_loss=0.516, loss=0.176, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 1:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.516, loss=0.176, REAL it/s=5.470, Kt/s=2.800]          \n",
      "Epoch 2:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.516, loss=0.176, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:   1%|          | 1/100 [00:00<00:36,  2.68it/s, lr=1e-5, sum_loss=0.516, loss=0.176, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:   1%|          | 1/100 [00:00<00:36,  2.68it/s, lr=1e-5, sum_loss=0.475, loss=0.475, REAL it/s=2.680, Kt/s=1.370]\n",
      "Epoch 2:   2%|▏         | 2/100 [00:00<00:27,  3.59it/s, lr=1e-5, sum_loss=0.475, loss=0.475, REAL it/s=2.680, Kt/s=1.370]\n",
      "Epoch 2:   2%|▏         | 2/100 [00:00<00:27,  3.59it/s, lr=1e-5, sum_loss=0.516, loss=0.559, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:   3%|▎         | 3/100 [00:00<00:24,  4.02it/s, lr=1e-5, sum_loss=0.516, loss=0.559, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:   3%|▎         | 3/100 [00:00<00:24,  4.02it/s, lr=1e-5, sum_loss=0.512, loss=0.508, REAL it/s=5.270, Kt/s=2.700]\n",
      "Epoch 2:   4%|▍         | 4/100 [00:00<00:22,  4.28it/s, lr=1e-5, sum_loss=0.512, loss=0.508, REAL it/s=5.270, Kt/s=2.700]\n",
      "Epoch 2:   4%|▍         | 4/100 [00:00<00:22,  4.28it/s, lr=1e-5, sum_loss=0.473, loss=0.350, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:   5%|▌         | 5/100 [00:01<00:21,  4.46it/s, lr=1e-5, sum_loss=0.473, loss=0.350, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:   5%|▌         | 5/100 [00:01<00:21,  4.46it/s, lr=1e-5, sum_loss=0.633, loss=1.270, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:   6%|▌         | 6/100 [00:01<00:20,  4.61it/s, lr=1e-5, sum_loss=0.633, loss=1.270, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:   6%|▌         | 6/100 [00:01<00:20,  4.60it/s, lr=1e-5, sum_loss=0.539, loss=0.0723, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:   7%|▋         | 7/100 [00:01<00:19,  4.70it/s, lr=1e-5, sum_loss=0.539, loss=0.0723, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:   7%|▋         | 7/100 [00:01<00:19,  4.69it/s, lr=1e-5, sum_loss=0.660, loss=1.380, REAL it/s=5.330, Kt/s=2.730] \n",
      "Epoch 2:   8%|▊         | 8/100 [00:01<00:19,  4.79it/s, lr=1e-5, sum_loss=0.660, loss=1.380, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:   8%|▊         | 8/100 [00:01<00:19,  4.79it/s, lr=1e-5, sum_loss=0.598, loss=0.155, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 2:   9%|▉         | 9/100 [00:01<00:18,  4.85it/s, lr=1e-5, sum_loss=0.598, loss=0.155, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 2:   9%|▉         | 9/100 [00:01<00:18,  4.85it/s, lr=1e-5, sum_loss=0.547, loss=0.116, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 2:  10%|█         | 10/100 [00:02<00:18,  4.90it/s, lr=1e-5, sum_loss=0.547, loss=0.116, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 2:  10%|█         | 10/100 [00:02<00:18,  4.89it/s, lr=1e-5, sum_loss=0.523, loss=0.336, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  11%|█         | 11/100 [00:02<00:18,  4.94it/s, lr=1e-5, sum_loss=0.523, loss=0.336, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  11%|█         | 11/100 [00:02<00:18,  4.94it/s, lr=1e-5, sum_loss=0.482, loss=0.0698, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:  12%|█▏        | 12/100 [00:02<00:17,  4.97it/s, lr=1e-5, sum_loss=0.482, loss=0.0698, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:  12%|█▏        | 12/100 [00:02<00:17,  4.97it/s, lr=1e-5, sum_loss=0.484, loss=0.512, REAL it/s=5.430, Kt/s=2.780] \n",
      "Epoch 2:  13%|█▎        | 13/100 [00:02<00:17,  5.01it/s, lr=1e-5, sum_loss=0.484, loss=0.512, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 2:  13%|█▎        | 13/100 [00:02<00:17,  5.01it/s, lr=1e-5, sum_loss=0.461, loss=0.188, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2:  14%|█▍        | 14/100 [00:02<00:17,  5.03it/s, lr=1e-5, sum_loss=0.461, loss=0.188, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2:  14%|█▍        | 14/100 [00:02<00:17,  5.03it/s, lr=1e-5, sum_loss=0.480, loss=0.719, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  15%|█▌        | 15/100 [00:02<00:16,  5.07it/s, lr=1e-5, sum_loss=0.480, loss=0.719, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  15%|█▌        | 15/100 [00:02<00:16,  5.07it/s, lr=1e-5, sum_loss=0.451, loss=0.0598, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 2:  16%|█▌        | 16/100 [00:03<00:16,  5.10it/s, lr=1e-5, sum_loss=0.451, loss=0.0598, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 2:  16%|█▌        | 16/100 [00:03<00:16,  5.10it/s, lr=1e-5, sum_loss=0.430, loss=0.101, REAL it/s=5.610, Kt/s=2.870] \n",
      "Epoch 2:  17%|█▋        | 17/100 [00:03<00:16,  5.13it/s, lr=1e-5, sum_loss=0.430, loss=0.101, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 2:  17%|█▋        | 17/100 [00:03<00:16,  5.13it/s, lr=1e-5, sum_loss=0.430, loss=0.445, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 2:  18%|█▊        | 18/100 [00:03<00:15,  5.16it/s, lr=1e-5, sum_loss=0.430, loss=0.445, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 2:  18%|█▊        | 18/100 [00:03<00:15,  5.16it/s, lr=1e-5, sum_loss=0.428, loss=0.363, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 2:  19%|█▉        | 19/100 [00:03<00:15,  5.18it/s, lr=1e-5, sum_loss=0.428, loss=0.363, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 2:  19%|█▉        | 19/100 [00:03<00:15,  5.18it/s, lr=1e-5, sum_loss=0.408, loss=0.0493, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 2:  20%|██        | 20/100 [00:03<00:15,  5.19it/s, lr=1e-5, sum_loss=0.408, loss=0.0493, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 2:  20%|██        | 20/100 [00:03<00:15,  5.19it/s, lr=1e-5, sum_loss=0.412, loss=0.504, REAL it/s=5.520, Kt/s=2.820] \n",
      "Epoch 2:  21%|██        | 21/100 [00:04<00:15,  5.21it/s, lr=1e-5, sum_loss=0.412, loss=0.504, REAL it/s=5.520, Kt/s=2.820]\n",
      "Epoch 2:  21%|██        | 21/100 [00:04<00:15,  5.21it/s, lr=1e-5, sum_loss=0.402, loss=0.201, REAL it/s=5.630, Kt/s=2.890]\n",
      "Epoch 2:  22%|██▏       | 22/100 [00:04<00:14,  5.23it/s, lr=1e-5, sum_loss=0.402, loss=0.201, REAL it/s=5.630, Kt/s=2.890]\n",
      "Epoch 2:  22%|██▏       | 22/100 [00:04<00:14,  5.23it/s, lr=1e-5, sum_loss=0.398, loss=0.320, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 2:  23%|██▎       | 23/100 [00:04<00:14,  5.24it/s, lr=1e-5, sum_loss=0.398, loss=0.320, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 2:  23%|██▎       | 23/100 [00:04<00:14,  5.24it/s, lr=1e-5, sum_loss=0.383, loss=0.0388, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 2:  24%|██▍       | 24/100 [00:04<00:14,  5.26it/s, lr=1e-5, sum_loss=0.383, loss=0.0388, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 2:  24%|██▍       | 24/100 [00:04<00:14,  5.26it/s, lr=1e-5, sum_loss=0.393, loss=0.598, REAL it/s=5.660, Kt/s=2.900] \n",
      "Epoch 2:  25%|██▌       | 25/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.393, loss=0.598, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 2:  25%|██▌       | 25/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.383, loss=0.102, REAL it/s=5.600, Kt/s=2.860]\n",
      "Epoch 2:  26%|██▌       | 26/100 [00:04<00:13,  5.29it/s, lr=1e-5, sum_loss=0.383, loss=0.102, REAL it/s=5.600, Kt/s=2.860]\n",
      "Epoch 2:  26%|██▌       | 26/100 [00:04<00:13,  5.29it/s, lr=1e-5, sum_loss=0.430, loss=1.620, REAL it/s=5.670, Kt/s=2.910]\n",
      "Epoch 2:  27%|██▋       | 27/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.430, loss=1.620, REAL it/s=5.670, Kt/s=2.910]\n",
      "Epoch 2:  27%|██▋       | 27/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.420, loss=0.132, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 2:  28%|██▊       | 28/100 [00:05<00:13,  5.30it/s, lr=1e-5, sum_loss=0.420, loss=0.132, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 2:  28%|██▊       | 28/100 [00:05<00:13,  5.30it/s, lr=1e-5, sum_loss=0.408, loss=0.104, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 2:  29%|██▉       | 29/100 [00:05<00:13,  5.31it/s, lr=1e-5, sum_loss=0.408, loss=0.104, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 2:  29%|██▉       | 29/100 [00:05<00:13,  5.31it/s, lr=1e-5, sum_loss=0.398, loss=0.125, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 2:  30%|███       | 30/100 [00:05<00:13,  5.32it/s, lr=1e-5, sum_loss=0.398, loss=0.125, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 2:  30%|███       | 30/100 [00:05<00:13,  5.32it/s, lr=1e-5, sum_loss=0.412, loss=0.793, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 2:  31%|███       | 31/100 [00:05<00:12,  5.33it/s, lr=1e-5, sum_loss=0.412, loss=0.793, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 2:  31%|███       | 31/100 [00:05<00:12,  5.33it/s, lr=1e-5, sum_loss=0.400, loss=0.0869, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  32%|███▏      | 32/100 [00:06<00:12,  5.33it/s, lr=1e-5, sum_loss=0.400, loss=0.0869, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  32%|███▏      | 32/100 [00:06<00:12,  5.33it/s, lr=1e-5, sum_loss=0.400, loss=0.393, REAL it/s=5.360, Kt/s=2.740] \n",
      "Epoch 2:  33%|███▎      | 33/100 [00:06<00:12,  5.33it/s, lr=1e-5, sum_loss=0.400, loss=0.393, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  33%|███▎      | 33/100 [00:06<00:12,  5.33it/s, lr=1e-5, sum_loss=0.396, loss=0.222, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 2:  34%|███▍      | 34/100 [00:06<00:12,  5.34it/s, lr=1e-5, sum_loss=0.396, loss=0.222, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 2:  34%|███▍      | 34/100 [00:06<00:12,  5.34it/s, lr=1e-5, sum_loss=0.389, loss=0.125, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:  35%|███▌      | 35/100 [00:06<00:12,  5.34it/s, lr=1e-5, sum_loss=0.389, loss=0.125, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:  35%|███▌      | 35/100 [00:06<00:12,  5.34it/s, lr=1e-5, sum_loss=0.377, loss=0.0251, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 2:  36%|███▌      | 36/100 [00:06<00:11,  5.35it/s, lr=1e-5, sum_loss=0.377, loss=0.0251, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 2:  36%|███▌      | 36/100 [00:06<00:11,  5.35it/s, lr=1e-5, sum_loss=0.375, loss=0.311, REAL it/s=5.540, Kt/s=2.840] \n",
      "Epoch 2:  37%|███▋      | 37/100 [00:06<00:11,  5.35it/s, lr=1e-5, sum_loss=0.375, loss=0.311, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 2:  37%|███▋      | 37/100 [00:06<00:11,  5.35it/s, lr=1e-5, sum_loss=0.365, loss=0.0259, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 2:  38%|███▊      | 38/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.365, loss=0.0259, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 2:  38%|███▊      | 38/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.400, loss=1.760, REAL it/s=5.610, Kt/s=2.870] \n",
      "Epoch 2:  39%|███▉      | 39/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.400, loss=1.760, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 2:  39%|███▉      | 39/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.398, loss=0.312, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 2:  40%|████      | 40/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.398, loss=0.312, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 2:  40%|████      | 40/100 [00:07<00:11,  5.36it/s, lr=1e-5, sum_loss=0.391, loss=0.0415, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  41%|████      | 41/100 [00:07<00:10,  5.37it/s, lr=1e-5, sum_loss=0.391, loss=0.0415, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  41%|████      | 41/100 [00:07<00:10,  5.37it/s, lr=1e-5, sum_loss=0.385, loss=0.107, REAL it/s=5.510, Kt/s=2.820] \n",
      "Epoch 2:  42%|████▏     | 42/100 [00:07<00:10,  5.38it/s, lr=1e-5, sum_loss=0.385, loss=0.107, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  42%|████▏     | 42/100 [00:07<00:10,  5.38it/s, lr=1e-5, sum_loss=0.377, loss=0.0535, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  43%|████▎     | 43/100 [00:07<00:10,  5.38it/s, lr=1e-5, sum_loss=0.377, loss=0.0535, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  43%|████▎     | 43/100 [00:07<00:10,  5.38it/s, lr=1e-5, sum_loss=0.369, loss=0.0603, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  44%|████▍     | 44/100 [00:08<00:10,  5.38it/s, lr=1e-5, sum_loss=0.369, loss=0.0603, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  44%|████▍     | 44/100 [00:08<00:10,  5.38it/s, lr=1e-5, sum_loss=0.363, loss=0.162, REAL it/s=5.330, Kt/s=2.730] \n",
      "Epoch 2:  45%|████▌     | 45/100 [00:08<00:10,  5.38it/s, lr=1e-5, sum_loss=0.363, loss=0.162, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  45%|████▌     | 45/100 [00:08<00:10,  5.38it/s, lr=1e-5, sum_loss=0.383, loss=1.230, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:  46%|████▌     | 46/100 [00:08<00:10,  5.37it/s, lr=1e-5, sum_loss=0.383, loss=1.230, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:  46%|████▌     | 46/100 [00:08<00:10,  5.37it/s, lr=1e-5, sum_loss=0.375, loss=0.0315, REAL it/s=5.290, Kt/s=2.710]\n",
      "Epoch 2:  47%|████▋     | 47/100 [00:08<00:09,  5.37it/s, lr=1e-5, sum_loss=0.375, loss=0.0315, REAL it/s=5.290, Kt/s=2.710]\n",
      "Epoch 2:  47%|████▋     | 47/100 [00:08<00:09,  5.37it/s, lr=1e-5, sum_loss=0.367, loss=0.0515, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 2:  48%|████▊     | 48/100 [00:08<00:09,  5.38it/s, lr=1e-5, sum_loss=0.367, loss=0.0515, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 2:  48%|████▊     | 48/100 [00:08<00:09,  5.38it/s, lr=1e-5, sum_loss=0.359, loss=0.0264, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  49%|████▉     | 49/100 [00:09<00:09,  5.38it/s, lr=1e-5, sum_loss=0.359, loss=0.0264, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  49%|████▉     | 49/100 [00:09<00:09,  5.38it/s, lr=1e-5, sum_loss=0.367, loss=0.742, REAL it/s=5.370, Kt/s=2.750] \n",
      "Epoch 2:  50%|█████     | 50/100 [00:09<00:09,  5.38it/s, lr=1e-5, sum_loss=0.367, loss=0.742, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 2:  50%|█████     | 50/100 [00:09<00:09,  5.38it/s, lr=1e-5, sum_loss=0.363, loss=0.173, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  51%|█████     | 51/100 [00:09<00:09,  5.37it/s, lr=1e-5, sum_loss=0.363, loss=0.173, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  51%|█████     | 51/100 [00:09<00:09,  5.37it/s, lr=1e-5, sum_loss=0.363, loss=0.320, REAL it/s=5.290, Kt/s=2.710]\n",
      "Epoch 2:  52%|█████▏    | 52/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.363, loss=0.320, REAL it/s=5.290, Kt/s=2.710]\n",
      "Epoch 2:  52%|█████▏    | 52/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.375, loss=0.949, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  53%|█████▎    | 53/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.375, loss=0.949, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  53%|█████▎    | 53/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.367, loss=0.0371, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 2:  54%|█████▍    | 54/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.367, loss=0.0371, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 2:  54%|█████▍    | 54/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.365, loss=0.221, REAL it/s=5.410, Kt/s=2.770] \n",
      "Epoch 2:  55%|█████▌    | 55/100 [00:10<00:08,  5.38it/s, lr=1e-5, sum_loss=0.365, loss=0.221, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  55%|█████▌    | 55/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.359, loss=0.0393, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 2:  56%|█████▌    | 56/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.359, loss=0.0393, REAL it/s=5.400, Kt/s=2.770]\n",
      "Epoch 2:  56%|█████▌    | 56/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.355, loss=0.109, REAL it/s=5.280, Kt/s=2.700] \n",
      "Epoch 2:  57%|█████▋    | 57/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.355, loss=0.109, REAL it/s=5.280, Kt/s=2.700]\n",
      "Epoch 2:  57%|█████▋    | 57/100 [00:10<00:08,  5.37it/s, lr=1e-5, sum_loss=0.352, loss=0.0654, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 2:  58%|█████▊    | 58/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.352, loss=0.0654, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 2:  58%|█████▊    | 58/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.367, loss=1.260, REAL it/s=5.370, Kt/s=2.750] \n",
      "Epoch 2:  59%|█████▉    | 59/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.367, loss=1.260, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 2:  59%|█████▉    | 59/100 [00:10<00:07,  5.37it/s, lr=1e-5, sum_loss=0.361, loss=0.0864, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  60%|██████    | 60/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.361, loss=0.0864, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  60%|██████    | 60/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.355, loss=0.0457, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 2:  61%|██████    | 61/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.355, loss=0.0457, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 2:  61%|██████    | 61/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.377, loss=1.590, REAL it/s=5.480, Kt/s=2.810] \n",
      "Epoch 2:  62%|██████▏   | 62/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.377, loss=1.590, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 2:  62%|██████▏   | 62/100 [00:11<00:07,  5.38it/s, lr=1e-5, sum_loss=0.391, loss=1.230, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2:  63%|██████▎   | 63/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.391, loss=1.230, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2:  63%|██████▎   | 63/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.387, loss=0.0786, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 2:  64%|██████▍   | 64/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.387, loss=0.0786, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 2:  64%|██████▍   | 64/100 [00:11<00:06,  5.38it/s, lr=1e-5, sum_loss=0.391, loss=0.570, REAL it/s=5.360, Kt/s=2.750] \n",
      "Epoch 2:  65%|██████▌   | 65/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.391, loss=0.570, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 2:  65%|██████▌   | 65/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.393, loss=0.465, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 2:  66%|██████▌   | 66/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.393, loss=0.465, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 2:  66%|██████▌   | 66/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.412, loss=1.690, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  67%|██████▋   | 67/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.412, loss=1.690, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  67%|██████▋   | 67/100 [00:12<00:06,  5.38it/s, lr=1e-5, sum_loss=0.408, loss=0.0908, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 2:  68%|██████▊   | 68/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.408, loss=0.0908, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 2:  68%|██████▊   | 68/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.404, loss=0.135, REAL it/s=5.600, Kt/s=2.860] \n",
      "Epoch 2:  69%|██████▉   | 69/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.404, loss=0.135, REAL it/s=5.600, Kt/s=2.860]\n",
      "Epoch 2:  69%|██████▉   | 69/100 [00:12<00:05,  5.38it/s, lr=1e-5, sum_loss=0.408, loss=0.680, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  70%|███████   | 70/100 [00:12<00:05,  5.39it/s, lr=1e-5, sum_loss=0.408, loss=0.680, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  70%|███████   | 70/100 [00:12<00:05,  5.39it/s, lr=1e-5, sum_loss=0.402, loss=0.0571, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  71%|███████   | 71/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.402, loss=0.0571, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  71%|███████   | 71/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.396, loss=0.0447, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  72%|███████▏  | 72/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.396, loss=0.0447, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  72%|███████▏  | 72/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.393, loss=0.084, REAL it/s=5.420, Kt/s=2.770] \n",
      "Epoch 2:  73%|███████▎  | 73/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.393, loss=0.084, REAL it/s=5.420, Kt/s=2.770]\n",
      "Epoch 2:  73%|███████▎  | 73/100 [00:13<00:05,  5.39it/s, lr=1e-5, sum_loss=0.387, loss=0.0322, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  74%|███████▍  | 74/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.387, loss=0.0322, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  74%|███████▍  | 74/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.385, loss=0.191, REAL it/s=5.530, Kt/s=2.830] \n",
      "Epoch 2:  75%|███████▌  | 75/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.385, loss=0.191, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 2:  75%|███████▌  | 75/100 [00:13<00:04,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.0327, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 2:  76%|███████▌  | 76/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.0327, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 2:  76%|███████▌  | 76/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.342, REAL it/s=5.490, Kt/s=2.810] \n",
      "Epoch 2:  77%|███████▋  | 77/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.342, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 2:  77%|███████▋  | 77/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.377, loss=0.164, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.377, loss=0.164, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.39it/s, lr=1e-5, sum_loss=0.379, loss=0.562, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  79%|███████▉  | 79/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.379, loss=0.562, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 2:  79%|███████▉  | 79/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.379, loss=0.504, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  80%|████████  | 80/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.379, loss=0.504, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  80%|████████  | 80/100 [00:14<00:03,  5.40it/s, lr=1e-5, sum_loss=0.381, loss=0.461, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  81%|████████  | 81/100 [00:15<00:03,  5.40it/s, lr=1e-5, sum_loss=0.381, loss=0.461, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 2:  81%|████████  | 81/100 [00:15<00:03,  5.40it/s, lr=1e-5, sum_loss=0.379, loss=0.135, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  82%|████████▏ | 82/100 [00:15<00:03,  5.39it/s, lr=1e-5, sum_loss=0.379, loss=0.135, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  82%|████████▏ | 82/100 [00:15<00:03,  5.39it/s, lr=1e-5, sum_loss=0.391, loss=1.480, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  83%|████████▎ | 83/100 [00:15<00:03,  5.39it/s, lr=1e-5, sum_loss=0.391, loss=1.480, REAL it/s=5.360, Kt/s=2.740]\n",
      "Epoch 2:  83%|████████▎ | 83/100 [00:15<00:03,  5.39it/s, lr=1e-5, sum_loss=0.385, loss=0.0598, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 2:  84%|████████▍ | 84/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.385, loss=0.0598, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 2:  84%|████████▍ | 84/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.116, REAL it/s=5.450, Kt/s=2.790] \n",
      "Epoch 2:  85%|████████▌ | 85/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.381, loss=0.116, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 2:  85%|████████▌ | 85/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.377, loss=0.0396, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:  86%|████████▌ | 86/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.377, loss=0.0396, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 2:  86%|████████▌ | 86/100 [00:15<00:02,  5.39it/s, lr=1e-5, sum_loss=0.373, loss=0.123, REAL it/s=5.360, Kt/s=2.750] \n",
      "Epoch 2:  87%|████████▋ | 87/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.373, loss=0.123, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 2:  87%|████████▋ | 87/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.367, loss=0.0449, REAL it/s=5.560, Kt/s=2.840]\n",
      "Epoch 2:  88%|████████▊ | 88/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.367, loss=0.0449, REAL it/s=5.560, Kt/s=2.840]\n",
      "Epoch 2:  88%|████████▊ | 88/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.363, loss=0.0317, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  89%|████████▉ | 89/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.363, loss=0.0317, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 2:  89%|████████▉ | 89/100 [00:16<00:02,  5.40it/s, lr=1e-5, sum_loss=0.359, loss=0.0574, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  90%|█████████ | 90/100 [00:16<00:01,  5.40it/s, lr=1e-5, sum_loss=0.359, loss=0.0574, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 2:  90%|█████████ | 90/100 [00:16<00:01,  5.40it/s, lr=1e-5, sum_loss=0.361, loss=0.387, REAL it/s=5.500, Kt/s=2.810] \n",
      "Epoch 2:  91%|█████████ | 91/100 [00:16<00:01,  5.40it/s, lr=1e-5, sum_loss=0.361, loss=0.387, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 2:  91%|█████████ | 91/100 [00:16<00:01,  5.40it/s, lr=1e-5, sum_loss=0.357, loss=0.0437, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 2:  92%|█████████▏| 92/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.357, loss=0.0437, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 2:  92%|█████████▏| 92/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.354, loss=0.0481, REAL it/s=5.320, Kt/s=2.730]\n",
      "Epoch 2:  93%|█████████▎| 93/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.354, loss=0.0481, REAL it/s=5.320, Kt/s=2.730]\n",
      "Epoch 2:  93%|█████████▎| 93/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.350, loss=0.109, REAL it/s=5.330, Kt/s=2.730] \n",
      "Epoch 2:  94%|█████████▍| 94/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.350, loss=0.109, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  94%|█████████▍| 94/100 [00:17<00:01,  5.40it/s, lr=1e-5, sum_loss=0.352, loss=0.469, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  95%|█████████▌| 95/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.352, loss=0.469, REAL it/s=5.460, Kt/s=2.800]\n",
      "Epoch 2:  95%|█████████▌| 95/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.350, loss=0.188, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 2:  96%|█████████▌| 96/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.350, loss=0.188, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 2:  96%|█████████▌| 96/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.346, loss=0.118, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 2:  97%|█████████▋| 97/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.346, loss=0.118, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 2:  97%|█████████▋| 97/100 [00:17<00:00,  5.40it/s, lr=1e-5, sum_loss=0.346, loss=0.190, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  98%|█████████▊| 98/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.346, loss=0.190, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 2:  98%|█████████▊| 98/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.344, loss=0.332, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 2:  99%|█████████▉| 99/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.344, loss=0.332, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 2:  99%|█████████▉| 99/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.344, loss=0.138, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2: 100%|██████████| 100/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.344, loss=0.138, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 2: 100%|██████████| 100/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.340, loss=0.0488, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2: 100%|██████████| 100/100 [00:18<00:00,  5.40it/s, lr=1e-5, sum_loss=0.340, loss=0.0488, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 2:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.340, loss=0.0488, REAL it/s=5.390, Kt/s=2.760]          \n",
      "Epoch 3:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.340, loss=0.0488, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:   1%|          | 1/100 [00:00<00:33,  2.96it/s, lr=1e-5, sum_loss=0.340, loss=0.0488, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:   1%|          | 1/100 [00:00<00:33,  2.95it/s, lr=1e-5, sum_loss=0.0317, loss=0.0317, REAL it/s=2.950, Kt/s=1.510]\n",
      "Epoch 3:   2%|▏         | 2/100 [00:00<00:25,  3.88it/s, lr=1e-5, sum_loss=0.0317, loss=0.0317, REAL it/s=2.950, Kt/s=1.510]\n",
      "Epoch 3:   2%|▏         | 2/100 [00:00<00:25,  3.87it/s, lr=1e-5, sum_loss=0.202, loss=0.373, REAL it/s=5.590, Kt/s=2.860]  \n",
      "Epoch 3:   3%|▎         | 3/100 [00:00<00:22,  4.31it/s, lr=1e-5, sum_loss=0.202, loss=0.373, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:   3%|▎         | 3/100 [00:00<00:22,  4.31it/s, lr=1e-5, sum_loss=0.142, loss=0.0195, REAL it/s=5.580, Kt/s=2.850]\n",
      "Epoch 3:   4%|▍         | 4/100 [00:00<00:21,  4.54it/s, lr=1e-5, sum_loss=0.142, loss=0.0195, REAL it/s=5.580, Kt/s=2.850]\n",
      "Epoch 3:   4%|▍         | 4/100 [00:00<00:21,  4.54it/s, lr=1e-5, sum_loss=0.217, loss=0.445, REAL it/s=5.410, Kt/s=2.770] \n",
      "Epoch 3:   5%|▌         | 5/100 [00:01<00:20,  4.71it/s, lr=1e-5, sum_loss=0.217, loss=0.445, REAL it/s=5.410, Kt/s=2.770]\n",
      "Epoch 3:   5%|▌         | 5/100 [00:01<00:20,  4.71it/s, lr=1e-5, sum_loss=0.186, loss=0.0579, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 3:   6%|▌         | 6/100 [00:01<00:19,  4.82it/s, lr=1e-5, sum_loss=0.186, loss=0.0579, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 3:   6%|▌         | 6/100 [00:01<00:19,  4.81it/s, lr=1e-5, sum_loss=0.200, loss=0.281, REAL it/s=5.430, Kt/s=2.780] \n",
      "Epoch 3:   7%|▋         | 7/100 [00:01<00:19,  4.89it/s, lr=1e-5, sum_loss=0.200, loss=0.281, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:   7%|▋         | 7/100 [00:01<00:19,  4.89it/s, lr=1e-5, sum_loss=0.188, loss=0.111, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:   8%|▊         | 8/100 [00:01<00:18,  4.97it/s, lr=1e-5, sum_loss=0.188, loss=0.111, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:   8%|▊         | 8/100 [00:01<00:18,  4.96it/s, lr=1e-5, sum_loss=0.182, loss=0.145, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:   9%|▉         | 9/100 [00:01<00:18,  5.02it/s, lr=1e-5, sum_loss=0.182, loss=0.145, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:   9%|▉         | 9/100 [00:01<00:18,  5.02it/s, lr=1e-5, sum_loss=0.176, loss=0.122, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  10%|█         | 10/100 [00:01<00:17,  5.06it/s, lr=1e-5, sum_loss=0.176, loss=0.122, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  10%|█         | 10/100 [00:01<00:17,  5.06it/s, lr=1e-5, sum_loss=0.169, loss=0.112, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 3:  11%|█         | 11/100 [00:02<00:17,  5.10it/s, lr=1e-5, sum_loss=0.169, loss=0.112, REAL it/s=5.400, Kt/s=2.760]\n",
      "Epoch 3:  11%|█         | 11/100 [00:02<00:17,  5.10it/s, lr=1e-5, sum_loss=0.179, loss=0.285, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:  12%|█▏        | 12/100 [00:02<00:17,  5.12it/s, lr=1e-5, sum_loss=0.179, loss=0.285, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:  12%|█▏        | 12/100 [00:02<00:17,  5.12it/s, lr=1e-5, sum_loss=0.168, loss=0.0413, REAL it/s=5.340, Kt/s=2.740]\n",
      "Epoch 3:  13%|█▎        | 13/100 [00:02<00:16,  5.14it/s, lr=1e-5, sum_loss=0.168, loss=0.0413, REAL it/s=5.340, Kt/s=2.740]\n",
      "Epoch 3:  13%|█▎        | 13/100 [00:02<00:16,  5.14it/s, lr=1e-5, sum_loss=0.165, loss=0.122, REAL it/s=5.350, Kt/s=2.740] \n",
      "Epoch 3:  14%|█▍        | 14/100 [00:02<00:16,  5.15it/s, lr=1e-5, sum_loss=0.165, loss=0.122, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 3:  14%|█▍        | 14/100 [00:02<00:16,  5.15it/s, lr=1e-5, sum_loss=0.158, loss=0.0845, REAL it/s=5.300, Kt/s=2.710]\n",
      "Epoch 3:  15%|█▌        | 15/100 [00:02<00:16,  5.17it/s, lr=1e-5, sum_loss=0.158, loss=0.0845, REAL it/s=5.300, Kt/s=2.710]\n",
      "Epoch 3:  15%|█▌        | 15/100 [00:02<00:16,  5.17it/s, lr=1e-5, sum_loss=0.150, loss=0.0359, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 3:  16%|█▌        | 16/100 [00:03<00:16,  5.19it/s, lr=1e-5, sum_loss=0.150, loss=0.0359, REAL it/s=5.490, Kt/s=2.810]\n",
      "Epoch 3:  16%|█▌        | 16/100 [00:03<00:16,  5.19it/s, lr=1e-5, sum_loss=0.143, loss=0.0374, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 3:  17%|█▋        | 17/100 [00:03<00:15,  5.20it/s, lr=1e-5, sum_loss=0.143, loss=0.0374, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 3:  17%|█▋        | 17/100 [00:03<00:15,  5.20it/s, lr=1e-5, sum_loss=0.139, loss=0.0767, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 3:  18%|█▊        | 18/100 [00:03<00:15,  5.21it/s, lr=1e-5, sum_loss=0.139, loss=0.0767, REAL it/s=5.420, Kt/s=2.780]\n",
      "Epoch 3:  18%|█▊        | 18/100 [00:03<00:15,  5.21it/s, lr=1e-5, sum_loss=0.136, loss=0.0737, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 3:  19%|█▉        | 19/100 [00:03<00:15,  5.22it/s, lr=1e-5, sum_loss=0.136, loss=0.0737, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 3:  19%|█▉        | 19/100 [00:03<00:15,  5.22it/s, lr=1e-5, sum_loss=0.148, loss=0.377, REAL it/s=5.340, Kt/s=2.740] \n",
      "Epoch 3:  20%|██        | 20/100 [00:03<00:15,  5.23it/s, lr=1e-5, sum_loss=0.148, loss=0.377, REAL it/s=5.340, Kt/s=2.740]\n",
      "Epoch 3:  20%|██        | 20/100 [00:03<00:15,  5.22it/s, lr=1e-5, sum_loss=0.229, loss=1.750, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 3:  21%|██        | 21/100 [00:04<00:15,  5.24it/s, lr=1e-5, sum_loss=0.229, loss=1.750, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 3:  21%|██        | 21/100 [00:04<00:15,  5.24it/s, lr=1e-5, sum_loss=0.224, loss=0.135, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 3:  22%|██▏       | 22/100 [00:04<00:14,  5.25it/s, lr=1e-5, sum_loss=0.224, loss=0.135, REAL it/s=5.470, Kt/s=2.800]\n",
      "Epoch 3:  22%|██▏       | 22/100 [00:04<00:14,  5.25it/s, lr=1e-5, sum_loss=0.264, loss=1.090, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 3:  23%|██▎       | 23/100 [00:04<00:14,  5.26it/s, lr=1e-5, sum_loss=0.264, loss=1.090, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 3:  23%|██▎       | 23/100 [00:04<00:14,  5.26it/s, lr=1e-5, sum_loss=0.252, loss=0.0181, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 3:  24%|██▍       | 24/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.252, loss=0.0181, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 3:  24%|██▍       | 24/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.295, loss=1.230, REAL it/s=5.480, Kt/s=2.800] \n",
      "Epoch 3:  25%|██▌       | 25/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.295, loss=1.230, REAL it/s=5.480, Kt/s=2.800]\n",
      "Epoch 3:  25%|██▌       | 25/100 [00:04<00:14,  5.27it/s, lr=1e-5, sum_loss=0.295, loss=0.312, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 3:  26%|██▌       | 26/100 [00:04<00:14,  5.28it/s, lr=1e-5, sum_loss=0.295, loss=0.312, REAL it/s=5.380, Kt/s=2.760]\n",
      "Epoch 3:  26%|██▌       | 26/100 [00:04<00:14,  5.28it/s, lr=1e-5, sum_loss=0.291, loss=0.194, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  27%|██▋       | 27/100 [00:05<00:13,  5.28it/s, lr=1e-5, sum_loss=0.291, loss=0.194, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  27%|██▋       | 27/100 [00:05<00:13,  5.28it/s, lr=1e-5, sum_loss=0.293, loss=0.334, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 3:  28%|██▊       | 28/100 [00:05<00:13,  5.28it/s, lr=1e-5, sum_loss=0.293, loss=0.334, REAL it/s=5.370, Kt/s=2.750]\n",
      "Epoch 3:  28%|██▊       | 28/100 [00:05<00:13,  5.28it/s, lr=1e-5, sum_loss=0.285, loss=0.0938, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 3:  29%|██▉       | 29/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.285, loss=0.0938, REAL it/s=5.350, Kt/s=2.740]\n",
      "Epoch 3:  29%|██▉       | 29/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.289, loss=0.346, REAL it/s=5.390, Kt/s=2.760] \n",
      "Epoch 3:  30%|███       | 30/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.289, loss=0.346, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:  30%|███       | 30/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.287, loss=0.241, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 3:  31%|███       | 31/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.287, loss=0.241, REAL it/s=5.330, Kt/s=2.730]\n",
      "Epoch 3:  31%|███       | 31/100 [00:05<00:13,  5.29it/s, lr=1e-5, sum_loss=0.311, loss=0.973, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  32%|███▏      | 32/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.311, loss=0.973, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  32%|███▏      | 32/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.303, loss=0.0571, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  33%|███▎      | 33/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.303, loss=0.0571, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  33%|███▎      | 33/100 [00:06<00:12,  5.30it/s, lr=1e-5, sum_loss=0.295, loss=0.0603, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 3:  34%|███▍      | 34/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.295, loss=0.0603, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 3:  34%|███▍      | 34/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.291, loss=0.115, REAL it/s=5.430, Kt/s=2.780] \n",
      "Epoch 3:  35%|███▌      | 35/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.291, loss=0.115, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  35%|███▌      | 35/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.297, loss=0.520, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  36%|███▌      | 36/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.297, loss=0.520, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  36%|███▌      | 36/100 [00:06<00:12,  5.31it/s, lr=1e-5, sum_loss=0.289, loss=0.050, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:  37%|███▋      | 37/100 [00:06<00:11,  5.31it/s, lr=1e-5, sum_loss=0.289, loss=0.050, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:  37%|███▋      | 37/100 [00:06<00:11,  5.31it/s, lr=1e-5, sum_loss=0.283, loss=0.0884, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  38%|███▊      | 38/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.283, loss=0.0884, REAL it/s=5.360, Kt/s=2.750]\n",
      "Epoch 3:  38%|███▊      | 38/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.279, loss=0.0996, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:  39%|███▉      | 39/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.279, loss=0.0996, REAL it/s=5.390, Kt/s=2.760]\n",
      "Epoch 3:  39%|███▉      | 39/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.275, loss=0.124, REAL it/s=5.320, Kt/s=2.720] \n",
      "Epoch 3:  40%|████      | 40/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.275, loss=0.124, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 3:  40%|████      | 40/100 [00:07<00:11,  5.32it/s, lr=1e-5, sum_loss=0.285, loss=0.707, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 3:  41%|████      | 41/100 [00:07<00:11,  5.31it/s, lr=1e-5, sum_loss=0.285, loss=0.707, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 3:  41%|████      | 41/100 [00:07<00:11,  5.31it/s, lr=1e-5, sum_loss=0.281, loss=0.125, REAL it/s=5.160, Kt/s=2.640]\n",
      "Epoch 3:  42%|████▏     | 42/100 [00:07<00:10,  5.32it/s, lr=1e-5, sum_loss=0.281, loss=0.125, REAL it/s=5.160, Kt/s=2.640]\n",
      "Epoch 3:  42%|████▏     | 42/100 [00:07<00:10,  5.32it/s, lr=1e-5, sum_loss=0.279, loss=0.215, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 3:  43%|████▎     | 43/100 [00:08<00:10,  5.33it/s, lr=1e-5, sum_loss=0.279, loss=0.215, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 3:  43%|████▎     | 43/100 [00:08<00:10,  5.33it/s, lr=1e-5, sum_loss=0.275, loss=0.0374, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 3:  44%|████▍     | 44/100 [00:08<00:10,  5.33it/s, lr=1e-5, sum_loss=0.275, loss=0.0374, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 3:  44%|████▍     | 44/100 [00:08<00:10,  5.33it/s, lr=1e-5, sum_loss=0.268, loss=0.0269, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 3:  45%|████▌     | 45/100 [00:08<00:10,  5.34it/s, lr=1e-5, sum_loss=0.268, loss=0.0269, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 3:  45%|████▌     | 45/100 [00:08<00:10,  5.34it/s, lr=1e-5, sum_loss=0.270, loss=0.334, REAL it/s=5.640, Kt/s=2.890] \n",
      "Epoch 3:  46%|████▌     | 46/100 [00:08<00:10,  5.34it/s, lr=1e-5, sum_loss=0.270, loss=0.334, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 3:  46%|████▌     | 46/100 [00:08<00:10,  5.34it/s, lr=1e-5, sum_loss=0.266, loss=0.0491, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 3:  47%|████▋     | 47/100 [00:08<00:09,  5.34it/s, lr=1e-5, sum_loss=0.266, loss=0.0491, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 3:  47%|████▋     | 47/100 [00:08<00:09,  5.34it/s, lr=1e-5, sum_loss=0.260, loss=0.0471, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 3:  48%|████▊     | 48/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.260, loss=0.0471, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 3:  48%|████▊     | 48/100 [00:08<00:09,  5.35it/s, lr=1e-5, sum_loss=0.258, loss=0.101, REAL it/s=5.500, Kt/s=2.820] \n",
      "Epoch 3:  49%|████▉     | 49/100 [00:09<00:09,  5.35it/s, lr=1e-5, sum_loss=0.258, loss=0.101, REAL it/s=5.500, Kt/s=2.820]\n",
      "Epoch 3:  49%|████▉     | 49/100 [00:09<00:09,  5.35it/s, lr=1e-5, sum_loss=0.254, loss=0.0417, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 3:  50%|█████     | 50/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.254, loss=0.0417, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 3:  50%|█████     | 50/100 [00:09<00:09,  5.36it/s, lr=1e-5, sum_loss=0.250, loss=0.0767, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 3:  51%|█████     | 51/100 [00:09<00:09,  5.37it/s, lr=1e-5, sum_loss=0.250, loss=0.0767, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 3:  51%|█████     | 51/100 [00:09<00:09,  5.37it/s, lr=1e-5, sum_loss=0.250, loss=0.247, REAL it/s=5.750, Kt/s=2.940] \n",
      "Epoch 3:  52%|█████▏    | 52/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.250, loss=0.247, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 3:  52%|█████▏    | 52/100 [00:09<00:08,  5.37it/s, lr=1e-5, sum_loss=0.252, loss=0.312, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 3:  53%|█████▎    | 53/100 [00:09<00:08,  5.38it/s, lr=1e-5, sum_loss=0.252, loss=0.312, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 3:  53%|█████▎    | 53/100 [00:09<00:08,  5.38it/s, lr=1e-5, sum_loss=0.246, loss=0.0215, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  54%|█████▍    | 54/100 [00:10<00:08,  5.38it/s, lr=1e-5, sum_loss=0.246, loss=0.0215, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  54%|█████▍    | 54/100 [00:10<00:08,  5.38it/s, lr=1e-5, sum_loss=0.242, loss=0.0302, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 3:  55%|█████▌    | 55/100 [00:10<00:08,  5.38it/s, lr=1e-5, sum_loss=0.242, loss=0.0302, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 3:  55%|█████▌    | 55/100 [00:10<00:08,  5.38it/s, lr=1e-5, sum_loss=0.237, loss=0.0165, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  56%|█████▌    | 56/100 [00:10<00:08,  5.39it/s, lr=1e-5, sum_loss=0.237, loss=0.0165, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  56%|█████▌    | 56/100 [00:10<00:08,  5.39it/s, lr=1e-5, sum_loss=0.235, loss=0.117, REAL it/s=5.540, Kt/s=2.830] \n",
      "Epoch 3:  57%|█████▋    | 57/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.235, loss=0.117, REAL it/s=5.540, Kt/s=2.830]\n",
      "Epoch 3:  57%|█████▋    | 57/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.232, loss=0.0884, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 3:  58%|█████▊    | 58/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.232, loss=0.0884, REAL it/s=5.440, Kt/s=2.790]\n",
      "Epoch 3:  58%|█████▊    | 58/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.229, loss=0.0182, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 3:  59%|█████▉    | 59/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.229, loss=0.0182, REAL it/s=5.480, Kt/s=2.810]\n",
      "Epoch 3:  59%|█████▉    | 59/100 [00:10<00:07,  5.39it/s, lr=1e-5, sum_loss=0.246, loss=1.230, REAL it/s=5.660, Kt/s=2.900] \n",
      "Epoch 3:  60%|██████    | 60/100 [00:11<00:07,  5.39it/s, lr=1e-5, sum_loss=0.246, loss=1.230, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  60%|██████    | 60/100 [00:11<00:07,  5.39it/s, lr=1e-5, sum_loss=0.248, loss=0.379, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  61%|██████    | 61/100 [00:11<00:07,  5.40it/s, lr=1e-5, sum_loss=0.248, loss=0.379, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  61%|██████    | 61/100 [00:11<00:07,  5.40it/s, lr=1e-5, sum_loss=0.245, loss=0.0762, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  62%|██████▏   | 62/100 [00:11<00:07,  5.40it/s, lr=1e-5, sum_loss=0.245, loss=0.0762, REAL it/s=5.430, Kt/s=2.780]\n",
      "Epoch 3:  62%|██████▏   | 62/100 [00:11<00:07,  5.40it/s, lr=1e-5, sum_loss=0.258, loss=0.980, REAL it/s=5.570, Kt/s=2.850] \n",
      "Epoch 3:  63%|██████▎   | 63/100 [00:11<00:06,  5.40it/s, lr=1e-5, sum_loss=0.258, loss=0.980, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 3:  63%|██████▎   | 63/100 [00:11<00:06,  5.40it/s, lr=1e-5, sum_loss=0.254, loss=0.0308, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 3:  64%|██████▍   | 64/100 [00:11<00:06,  5.41it/s, lr=1e-5, sum_loss=0.254, loss=0.0308, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 3:  64%|██████▍   | 64/100 [00:11<00:06,  5.41it/s, lr=1e-5, sum_loss=0.250, loss=0.0378, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 3:  65%|██████▌   | 65/100 [00:12<00:06,  5.41it/s, lr=1e-5, sum_loss=0.250, loss=0.0378, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 3:  65%|██████▌   | 65/100 [00:12<00:06,  5.41it/s, lr=1e-5, sum_loss=0.266, loss=1.270, REAL it/s=5.660, Kt/s=2.900] \n",
      "Epoch 3:  66%|██████▌   | 66/100 [00:12<00:06,  5.41it/s, lr=1e-5, sum_loss=0.266, loss=1.270, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  66%|██████▌   | 66/100 [00:12<00:06,  5.41it/s, lr=1e-5, sum_loss=0.281, loss=1.190, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 3:  67%|██████▋   | 67/100 [00:12<00:06,  5.42it/s, lr=1e-5, sum_loss=0.281, loss=1.190, REAL it/s=5.500, Kt/s=2.810]\n",
      "Epoch 3:  67%|██████▋   | 67/100 [00:12<00:06,  5.42it/s, lr=1e-5, sum_loss=0.275, loss=0.0288, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  68%|██████▊   | 68/100 [00:12<00:05,  5.42it/s, lr=1e-5, sum_loss=0.275, loss=0.0288, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 3:  68%|██████▊   | 68/100 [00:12<00:05,  5.42it/s, lr=1e-5, sum_loss=0.271, loss=0.022, REAL it/s=5.740, Kt/s=2.940] \n",
      "Epoch 3:  69%|██████▉   | 69/100 [00:12<00:05,  5.42it/s, lr=1e-5, sum_loss=0.271, loss=0.022, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 3:  69%|██████▉   | 69/100 [00:12<00:05,  5.42it/s, lr=1e-5, sum_loss=0.268, loss=0.00497, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 3:  70%|███████   | 70/100 [00:12<00:05,  5.43it/s, lr=1e-5, sum_loss=0.268, loss=0.00497, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 3:  70%|███████   | 70/100 [00:12<00:05,  5.43it/s, lr=1e-5, sum_loss=0.266, loss=0.114, REAL it/s=5.520, Kt/s=2.830]  \n",
      "Epoch 3:  71%|███████   | 71/100 [00:13<00:05,  5.43it/s, lr=1e-5, sum_loss=0.266, loss=0.114, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 3:  71%|███████   | 71/100 [00:13<00:05,  5.43it/s, lr=1e-5, sum_loss=0.262, loss=0.0537, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 3:  72%|███████▏  | 72/100 [00:13<00:05,  5.43it/s, lr=1e-5, sum_loss=0.262, loss=0.0537, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 3:  72%|███████▏  | 72/100 [00:13<00:05,  5.43it/s, lr=1e-5, sum_loss=0.258, loss=0.0126, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 3:  73%|███████▎  | 73/100 [00:13<00:04,  5.43it/s, lr=1e-5, sum_loss=0.258, loss=0.0126, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 3:  73%|███████▎  | 73/100 [00:13<00:04,  5.43it/s, lr=1e-5, sum_loss=0.256, loss=0.0142, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 3:  74%|███████▍  | 74/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.256, loss=0.0142, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 3:  74%|███████▍  | 74/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.252, loss=0.0309, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 3:  75%|███████▌  | 75/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.252, loss=0.0309, REAL it/s=5.540, Kt/s=2.840]\n",
      "Epoch 3:  75%|███████▌  | 75/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.266, loss=1.270, REAL it/s=5.510, Kt/s=2.820] \n",
      "Epoch 3:  76%|███████▌  | 76/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.266, loss=1.270, REAL it/s=5.510, Kt/s=2.820]\n",
      "Epoch 3:  76%|███████▌  | 76/100 [00:13<00:04,  5.44it/s, lr=1e-5, sum_loss=0.262, loss=0.0532, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 3:  77%|███████▋  | 77/100 [00:14<00:04,  5.44it/s, lr=1e-5, sum_loss=0.262, loss=0.0532, REAL it/s=5.450, Kt/s=2.790]\n",
      "Epoch 3:  77%|███████▋  | 77/100 [00:14<00:04,  5.44it/s, lr=1e-5, sum_loss=0.258, loss=0.0201, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.44it/s, lr=1e-5, sum_loss=0.258, loss=0.0201, REAL it/s=5.340, Kt/s=2.730]\n",
      "Epoch 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.44it/s, lr=1e-5, sum_loss=0.256, loss=0.140, REAL it/s=5.530, Kt/s=2.830] \n",
      "Epoch 3:  79%|███████▉  | 79/100 [00:14<00:03,  5.43it/s, lr=1e-5, sum_loss=0.256, loss=0.140, REAL it/s=5.530, Kt/s=2.830]\n",
      "Epoch 3:  79%|███████▉  | 79/100 [00:14<00:03,  5.43it/s, lr=1e-5, sum_loss=0.254, loss=0.161, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 3:  80%|████████  | 80/100 [00:14<00:03,  5.43it/s, lr=1e-5, sum_loss=0.254, loss=0.161, REAL it/s=5.320, Kt/s=2.720]\n",
      "Epoch 3:  80%|████████  | 80/100 [00:14<00:03,  5.43it/s, lr=1e-5, sum_loss=0.260, loss=0.617, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 3:  81%|████████  | 81/100 [00:14<00:03,  5.44it/s, lr=1e-5, sum_loss=0.260, loss=0.617, REAL it/s=5.380, Kt/s=2.750]\n",
      "Epoch 3:  81%|████████  | 81/100 [00:14<00:03,  5.44it/s, lr=1e-5, sum_loss=0.258, loss=0.165, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 3:  82%|████████▏ | 82/100 [00:15<00:03,  5.44it/s, lr=1e-5, sum_loss=0.258, loss=0.165, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 3:  82%|████████▏ | 82/100 [00:15<00:03,  5.44it/s, lr=1e-5, sum_loss=0.254, loss=0.0253, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 3:  83%|████████▎ | 83/100 [00:15<00:03,  5.45it/s, lr=1e-5, sum_loss=0.254, loss=0.0253, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 3:  83%|████████▎ | 83/100 [00:15<00:03,  5.45it/s, lr=1e-5, sum_loss=0.260, loss=0.703, REAL it/s=5.870, Kt/s=3.010] \n",
      "Epoch 3:  84%|████████▍ | 84/100 [00:15<00:02,  5.45it/s, lr=1e-5, sum_loss=0.260, loss=0.703, REAL it/s=5.870, Kt/s=3.010]\n",
      "Epoch 3:  84%|████████▍ | 84/100 [00:15<00:02,  5.45it/s, lr=1e-5, sum_loss=0.258, loss=0.0579, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 3:  85%|████████▌ | 85/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.258, loss=0.0579, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 3:  85%|████████▌ | 85/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.256, loss=0.0649, REAL it/s=5.970, Kt/s=3.050]\n",
      "Epoch 3:  86%|████████▌ | 86/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.256, loss=0.0649, REAL it/s=5.970, Kt/s=3.050]\n",
      "Epoch 3:  86%|████████▌ | 86/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.254, loss=0.0967, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 3:  87%|████████▋ | 87/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.254, loss=0.0967, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 3:  87%|████████▋ | 87/100 [00:15<00:02,  5.46it/s, lr=1e-5, sum_loss=0.254, loss=0.271, REAL it/s=5.910, Kt/s=3.030] \n",
      "Epoch 3:  88%|████████▊ | 88/100 [00:16<00:02,  5.47it/s, lr=1e-5, sum_loss=0.254, loss=0.271, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 3:  88%|████████▊ | 88/100 [00:16<00:02,  5.47it/s, lr=1e-5, sum_loss=0.252, loss=0.0664, REAL it/s=6.010, Kt/s=3.080]\n",
      "Epoch 3:  89%|████████▉ | 89/100 [00:16<00:02,  5.47it/s, lr=1e-5, sum_loss=0.252, loss=0.0664, REAL it/s=6.010, Kt/s=3.080]\n",
      "Epoch 3:  89%|████████▉ | 89/100 [00:16<00:02,  5.47it/s, lr=1e-5, sum_loss=0.250, loss=0.0221, REAL it/s=5.890, Kt/s=3.010]\n",
      "Epoch 3:  90%|█████████ | 90/100 [00:16<00:01,  5.48it/s, lr=1e-5, sum_loss=0.250, loss=0.0221, REAL it/s=5.890, Kt/s=3.010]\n",
      "Epoch 3:  90%|█████████ | 90/100 [00:16<00:01,  5.48it/s, lr=1e-5, sum_loss=0.249, loss=0.157, REAL it/s=5.910, Kt/s=3.030] \n",
      "Epoch 3:  91%|█████████ | 91/100 [00:16<00:01,  5.48it/s, lr=1e-5, sum_loss=0.249, loss=0.157, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 3:  91%|█████████ | 91/100 [00:16<00:01,  5.48it/s, lr=1e-5, sum_loss=0.247, loss=0.0723, REAL it/s=5.970, Kt/s=3.060]\n",
      "Epoch 3:  92%|█████████▏| 92/100 [00:16<00:01,  5.49it/s, lr=1e-5, sum_loss=0.247, loss=0.0723, REAL it/s=5.970, Kt/s=3.060]\n",
      "Epoch 3:  92%|█████████▏| 92/100 [00:16<00:01,  5.49it/s, lr=1e-5, sum_loss=0.247, loss=0.193, REAL it/s=5.810, Kt/s=2.980] \n",
      "Epoch 3:  93%|█████████▎| 93/100 [00:16<00:01,  5.49it/s, lr=1e-5, sum_loss=0.247, loss=0.193, REAL it/s=5.810, Kt/s=2.980]\n",
      "Epoch 3:  93%|█████████▎| 93/100 [00:16<00:01,  5.49it/s, lr=1e-5, sum_loss=0.249, loss=0.383, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 3:  94%|█████████▍| 94/100 [00:17<00:01,  5.49it/s, lr=1e-5, sum_loss=0.249, loss=0.383, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 3:  94%|█████████▍| 94/100 [00:17<00:01,  5.49it/s, lr=1e-5, sum_loss=0.247, loss=0.112, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 3:  95%|█████████▌| 95/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.247, loss=0.112, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 3:  95%|█████████▌| 95/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.245, loss=0.0184, REAL it/s=5.790, Kt/s=2.960]\n",
      "Epoch 3:  96%|█████████▌| 96/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.245, loss=0.0184, REAL it/s=5.790, Kt/s=2.960]\n",
      "Epoch 3:  96%|█████████▌| 96/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.243, loss=0.160, REAL it/s=5.590, Kt/s=2.860] \n",
      "Epoch 3:  97%|█████████▋| 97/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.243, loss=0.160, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 3:  97%|█████████▋| 97/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.256, loss=1.490, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 3:  98%|█████████▊| 98/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.256, loss=1.490, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 3:  98%|█████████▊| 98/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.254, loss=0.0258, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 3:  99%|█████████▉| 99/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.254, loss=0.0258, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 3:  99%|█████████▉| 99/100 [00:17<00:00,  5.50it/s, lr=1e-5, sum_loss=0.254, loss=0.194, REAL it/s=5.750, Kt/s=2.940] \n",
      "Epoch 3: 100%|██████████| 100/100 [00:18<00:00,  5.51it/s, lr=1e-5, sum_loss=0.254, loss=0.194, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 3: 100%|██████████| 100/100 [00:18<00:00,  5.51it/s, lr=1e-5, sum_loss=0.252, loss=0.00891, REAL it/s=5.810, Kt/s=2.970]\n",
      "Epoch 3: 100%|██████████| 100/100 [00:18<00:00,  5.51it/s, lr=1e-5, sum_loss=0.252, loss=0.00891, REAL it/s=5.810, Kt/s=2.970]\n",
      "Epoch 3:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.252, loss=0.00891, REAL it/s=5.810, Kt/s=2.970]          \n",
      "Epoch 4:   0%|          | 0/100 [00:00<?, ?it/s, lr=1e-5, sum_loss=0.252, loss=0.00891, REAL it/s=5.810, Kt/s=2.970]\n",
      "Epoch 4:   1%|          | 1/100 [00:00<00:35,  2.80it/s, lr=1e-5, sum_loss=0.252, loss=0.00891, REAL it/s=5.810, Kt/s=2.970]\n",
      "Epoch 4:   1%|          | 1/100 [00:00<00:35,  2.80it/s, lr=1e-5, sum_loss=0.0227, loss=0.0227, REAL it/s=2.800, Kt/s=1.440]\n",
      "Epoch 4:   2%|▏         | 2/100 [00:00<00:25,  3.81it/s, lr=1e-5, sum_loss=0.0227, loss=0.0227, REAL it/s=2.800, Kt/s=1.440]\n",
      "Epoch 4:   2%|▏         | 2/100 [00:00<00:25,  3.81it/s, lr=1e-5, sum_loss=0.121, loss=0.219, REAL it/s=5.910, Kt/s=3.020]  \n",
      "Epoch 4:   3%|▎         | 3/100 [00:00<00:22,  4.31it/s, lr=1e-5, sum_loss=0.121, loss=0.219, REAL it/s=5.910, Kt/s=3.020]\n",
      "Epoch 4:   3%|▎         | 3/100 [00:00<00:22,  4.31it/s, lr=1e-5, sum_loss=0.105, loss=0.0737, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:   4%|▍         | 4/100 [00:00<00:20,  4.63it/s, lr=1e-5, sum_loss=0.105, loss=0.0737, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:   4%|▍         | 4/100 [00:00<00:20,  4.63it/s, lr=1e-5, sum_loss=0.0864, loss=0.0315, REAL it/s=5.930, Kt/s=3.030]\n",
      "Epoch 4:   5%|▌         | 5/100 [00:01<00:19,  4.84it/s, lr=1e-5, sum_loss=0.0864, loss=0.0315, REAL it/s=5.930, Kt/s=3.030]\n",
      "Epoch 4:   5%|▌         | 5/100 [00:01<00:19,  4.84it/s, lr=1e-5, sum_loss=0.135, loss=0.330, REAL it/s=5.890, Kt/s=3.020]  \n",
      "Epoch 4:   6%|▌         | 6/100 [00:01<00:18,  4.98it/s, lr=1e-5, sum_loss=0.135, loss=0.330, REAL it/s=5.890, Kt/s=3.020]\n",
      "Epoch 4:   6%|▌         | 6/100 [00:01<00:18,  4.98it/s, lr=1e-5, sum_loss=0.130, loss=0.105, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:   7%|▋         | 7/100 [00:01<00:18,  5.09it/s, lr=1e-5, sum_loss=0.130, loss=0.105, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:   7%|▋         | 7/100 [00:01<00:18,  5.09it/s, lr=1e-5, sum_loss=0.142, loss=0.210, REAL it/s=5.890, Kt/s=3.020]\n",
      "Epoch 4:   8%|▊         | 8/100 [00:01<00:17,  5.18it/s, lr=1e-5, sum_loss=0.142, loss=0.210, REAL it/s=5.890, Kt/s=3.020]\n",
      "Epoch 4:   8%|▊         | 8/100 [00:01<00:17,  5.18it/s, lr=1e-5, sum_loss=0.143, loss=0.148, REAL it/s=5.890, Kt/s=3.020]\n",
      "Epoch 4:   9%|▉         | 9/100 [00:01<00:17,  5.24it/s, lr=1e-5, sum_loss=0.143, loss=0.148, REAL it/s=5.890, Kt/s=3.020]\n",
      "Epoch 4:   9%|▉         | 9/100 [00:01<00:17,  5.24it/s, lr=1e-5, sum_loss=0.152, loss=0.233, REAL it/s=5.810, Kt/s=2.980]\n",
      "Epoch 4:  10%|█         | 10/100 [00:01<00:16,  5.30it/s, lr=1e-5, sum_loss=0.152, loss=0.233, REAL it/s=5.810, Kt/s=2.980]\n",
      "Epoch 4:  10%|█         | 10/100 [00:01<00:16,  5.30it/s, lr=1e-5, sum_loss=0.139, loss=0.00696, REAL it/s=5.860, Kt/s=3.000]\n",
      "Epoch 4:  11%|█         | 11/100 [00:02<00:16,  5.34it/s, lr=1e-5, sum_loss=0.139, loss=0.00696, REAL it/s=5.860, Kt/s=3.000]\n",
      "Epoch 4:  11%|█         | 11/100 [00:02<00:16,  5.34it/s, lr=1e-5, sum_loss=0.129, loss=0.041, REAL it/s=5.860, Kt/s=3.000]  \n",
      "Epoch 4:  12%|█▏        | 12/100 [00:02<00:16,  5.37it/s, lr=1e-5, sum_loss=0.129, loss=0.041, REAL it/s=5.860, Kt/s=3.000]\n",
      "Epoch 4:  12%|█▏        | 12/100 [00:02<00:16,  5.37it/s, lr=1e-5, sum_loss=0.122, loss=0.0364, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 4:  13%|█▎        | 13/100 [00:02<00:16,  5.40it/s, lr=1e-5, sum_loss=0.122, loss=0.0364, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 4:  13%|█▎        | 13/100 [00:02<00:16,  5.40it/s, lr=1e-5, sum_loss=0.112, loss=0.00246, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:  14%|█▍        | 14/100 [00:02<00:15,  5.42it/s, lr=1e-5, sum_loss=0.112, loss=0.00246, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:  14%|█▍        | 14/100 [00:02<00:15,  5.42it/s, lr=1e-5, sum_loss=0.120, loss=0.222, REAL it/s=5.660, Kt/s=2.900]  \n",
      "Epoch 4:  15%|█▌        | 15/100 [00:02<00:15,  5.44it/s, lr=1e-5, sum_loss=0.120, loss=0.222, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  15%|█▌        | 15/100 [00:02<00:15,  5.44it/s, lr=1e-5, sum_loss=0.184, loss=1.060, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 4:  16%|█▌        | 16/100 [00:02<00:15,  5.45it/s, lr=1e-5, sum_loss=0.184, loss=1.060, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 4:  16%|█▌        | 16/100 [00:02<00:15,  5.44it/s, lr=1e-5, sum_loss=0.173, loss=0.00897, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 4:  17%|█▋        | 17/100 [00:03<00:15,  5.45it/s, lr=1e-5, sum_loss=0.173, loss=0.00897, REAL it/s=5.590, Kt/s=2.860]\n",
      "Epoch 4:  17%|█▋        | 17/100 [00:03<00:15,  5.45it/s, lr=1e-5, sum_loss=0.179, loss=0.271, REAL it/s=5.580, Kt/s=2.860]  \n",
      "Epoch 4:  18%|█▊        | 18/100 [00:03<00:14,  5.47it/s, lr=1e-5, sum_loss=0.179, loss=0.271, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 4:  18%|█▊        | 18/100 [00:03<00:14,  5.47it/s, lr=1e-5, sum_loss=0.245, loss=1.380, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 4:  19%|█▉        | 19/100 [00:03<00:14,  5.48it/s, lr=1e-5, sum_loss=0.245, loss=1.380, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 4:  19%|█▉        | 19/100 [00:03<00:14,  5.48it/s, lr=1e-5, sum_loss=0.231, loss=0.0148, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 4:  20%|██        | 20/100 [00:03<00:14,  5.50it/s, lr=1e-5, sum_loss=0.231, loss=0.0148, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 4:  20%|██        | 20/100 [00:03<00:14,  5.50it/s, lr=1e-5, sum_loss=0.222, loss=0.0304, REAL it/s=5.830, Kt/s=2.990]\n",
      "Epoch 4:  21%|██        | 21/100 [00:03<00:14,  5.50it/s, lr=1e-5, sum_loss=0.222, loss=0.0304, REAL it/s=5.830, Kt/s=2.990]\n",
      "Epoch 4:  21%|██        | 21/100 [00:03<00:14,  5.50it/s, lr=1e-5, sum_loss=0.211, loss=0.0143, REAL it/s=5.670, Kt/s=2.900]\n",
      "Epoch 4:  22%|██▏       | 22/100 [00:03<00:14,  5.52it/s, lr=1e-5, sum_loss=0.211, loss=0.0143, REAL it/s=5.670, Kt/s=2.900]\n",
      "Epoch 4:  22%|██▏       | 22/100 [00:03<00:14,  5.52it/s, lr=1e-5, sum_loss=0.206, loss=0.0898, REAL it/s=5.830, Kt/s=2.990]\n",
      "Epoch 4:  23%|██▎       | 23/100 [00:04<00:13,  5.53it/s, lr=1e-5, sum_loss=0.206, loss=0.0898, REAL it/s=5.830, Kt/s=2.990]\n",
      "Epoch 4:  23%|██▎       | 23/100 [00:04<00:13,  5.53it/s, lr=1e-5, sum_loss=0.215, loss=0.408, REAL it/s=5.710, Kt/s=2.930] \n",
      "Epoch 4:  24%|██▍       | 24/100 [00:04<00:13,  5.53it/s, lr=1e-5, sum_loss=0.215, loss=0.408, REAL it/s=5.710, Kt/s=2.930]\n",
      "Epoch 4:  24%|██▍       | 24/100 [00:04<00:13,  5.53it/s, lr=1e-5, sum_loss=0.206, loss=0.00934, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 4:  25%|██▌       | 25/100 [00:04<00:13,  5.54it/s, lr=1e-5, sum_loss=0.206, loss=0.00934, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 4:  25%|██▌       | 25/100 [00:04<00:13,  5.54it/s, lr=1e-5, sum_loss=0.197, loss=0.0105, REAL it/s=5.710, Kt/s=2.920] \n",
      "Epoch 4:  26%|██▌       | 26/100 [00:04<00:13,  5.54it/s, lr=1e-5, sum_loss=0.197, loss=0.0105, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 4:  26%|██▌       | 26/100 [00:04<00:13,  5.54it/s, lr=1e-5, sum_loss=0.189, loss=0.0125, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  27%|██▋       | 27/100 [00:04<00:13,  5.55it/s, lr=1e-5, sum_loss=0.189, loss=0.0125, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  27%|██▋       | 27/100 [00:04<00:13,  5.55it/s, lr=1e-5, sum_loss=0.196, loss=0.369, REAL it/s=5.610, Kt/s=2.870] \n",
      "Epoch 4:  28%|██▊       | 28/100 [00:05<00:12,  5.56it/s, lr=1e-5, sum_loss=0.196, loss=0.369, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 4:  28%|██▊       | 28/100 [00:05<00:12,  5.56it/s, lr=1e-5, sum_loss=0.190, loss=0.0264, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  29%|██▉       | 29/100 [00:05<00:12,  5.57it/s, lr=1e-5, sum_loss=0.190, loss=0.0264, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  29%|██▉       | 29/100 [00:05<00:12,  5.57it/s, lr=1e-5, sum_loss=0.216, loss=0.906, REAL it/s=5.960, Kt/s=3.050] \n",
      "Epoch 4:  30%|███       | 30/100 [00:05<00:12,  5.59it/s, lr=1e-5, sum_loss=0.216, loss=0.906, REAL it/s=5.960, Kt/s=3.050]\n",
      "Epoch 4:  30%|███       | 30/100 [00:05<00:12,  5.59it/s, lr=1e-5, sum_loss=0.236, loss=0.832, REAL it/s=6.020, Kt/s=3.080]\n",
      "Epoch 4:  31%|███       | 31/100 [00:05<00:12,  5.59it/s, lr=1e-5, sum_loss=0.236, loss=0.832, REAL it/s=6.020, Kt/s=3.080]\n",
      "Epoch 4:  31%|███       | 31/100 [00:05<00:12,  5.59it/s, lr=1e-5, sum_loss=0.232, loss=0.129, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  32%|███▏      | 32/100 [00:05<00:12,  5.60it/s, lr=1e-5, sum_loss=0.232, loss=0.129, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  32%|███▏      | 32/100 [00:05<00:12,  5.60it/s, lr=1e-5, sum_loss=0.226, loss=0.0135, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  33%|███▎      | 33/100 [00:05<00:11,  5.61it/s, lr=1e-5, sum_loss=0.226, loss=0.0135, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  33%|███▎      | 33/100 [00:05<00:11,  5.61it/s, lr=1e-5, sum_loss=0.219, loss=0.0153, REAL it/s=5.940, Kt/s=3.040]\n",
      "Epoch 4:  34%|███▍      | 34/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.219, loss=0.0153, REAL it/s=5.940, Kt/s=3.040]\n",
      "Epoch 4:  34%|███▍      | 34/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.214, loss=0.0542, REAL it/s=5.870, Kt/s=3.000]\n",
      "Epoch 4:  35%|███▌      | 35/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.214, loss=0.0542, REAL it/s=5.870, Kt/s=3.000]\n",
      "Epoch 4:  35%|███▌      | 35/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.209, loss=0.0359, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 4:  36%|███▌      | 36/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.209, loss=0.0359, REAL it/s=5.620, Kt/s=2.880]\n",
      "Epoch 4:  36%|███▌      | 36/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.204, loss=0.0195, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 4:  37%|███▋      | 37/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.204, loss=0.0195, REAL it/s=5.680, Kt/s=2.910]\n",
      "Epoch 4:  37%|███▋      | 37/100 [00:06<00:11,  5.62it/s, lr=1e-5, sum_loss=0.205, loss=0.264, REAL it/s=5.710, Kt/s=2.920] \n",
      "Epoch 4:  38%|███▊      | 38/100 [00:06<00:11,  5.63it/s, lr=1e-5, sum_loss=0.205, loss=0.264, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 4:  38%|███▊      | 38/100 [00:06<00:11,  5.63it/s, lr=1e-5, sum_loss=0.200, loss=0.0181, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 4:  39%|███▉      | 39/100 [00:06<00:10,  5.64it/s, lr=1e-5, sum_loss=0.200, loss=0.0181, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 4:  39%|███▉      | 39/100 [00:06<00:10,  5.64it/s, lr=1e-5, sum_loss=0.198, loss=0.0962, REAL it/s=5.970, Kt/s=3.060]\n",
      "Epoch 4:  40%|████      | 40/100 [00:07<00:10,  5.64it/s, lr=1e-5, sum_loss=0.198, loss=0.0962, REAL it/s=5.970, Kt/s=3.060]\n",
      "Epoch 4:  40%|████      | 40/100 [00:07<00:10,  5.64it/s, lr=1e-5, sum_loss=0.193, loss=0.0342, REAL it/s=5.960, Kt/s=3.050]\n",
      "Epoch 4:  41%|████      | 41/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.193, loss=0.0342, REAL it/s=5.960, Kt/s=3.050]\n",
      "Epoch 4:  41%|████      | 41/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.194, loss=0.220, REAL it/s=5.700, Kt/s=2.920] \n",
      "Epoch 4:  42%|████▏     | 42/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.194, loss=0.220, REAL it/s=5.700, Kt/s=2.920]\n",
      "Epoch 4:  42%|████▏     | 42/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.190, loss=0.0222, REAL it/s=5.820, Kt/s=2.980]\n",
      "Epoch 4:  43%|████▎     | 43/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.190, loss=0.0222, REAL it/s=5.820, Kt/s=2.980]\n",
      "Epoch 4:  43%|████▎     | 43/100 [00:07<00:10,  5.65it/s, lr=1e-5, sum_loss=0.188, loss=0.0554, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 4:  44%|████▍     | 44/100 [00:07<00:09,  5.65it/s, lr=1e-5, sum_loss=0.188, loss=0.0554, REAL it/s=5.710, Kt/s=2.920]\n",
      "Epoch 4:  44%|████▍     | 44/100 [00:07<00:09,  5.65it/s, lr=1e-5, sum_loss=0.184, loss=0.0134, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 4:  45%|████▌     | 45/100 [00:07<00:09,  5.66it/s, lr=1e-5, sum_loss=0.184, loss=0.0134, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 4:  45%|████▌     | 45/100 [00:07<00:09,  5.66it/s, lr=1e-5, sum_loss=0.181, loss=0.0566, REAL it/s=5.910, Kt/s=3.020]\n",
      "Epoch 4:  46%|████▌     | 46/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.181, loss=0.0566, REAL it/s=5.910, Kt/s=3.020]\n",
      "Epoch 4:  46%|████▌     | 46/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.195, loss=0.867, REAL it/s=5.670, Kt/s=2.900] \n",
      "Epoch 4:  47%|████▋     | 47/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.195, loss=0.867, REAL it/s=5.670, Kt/s=2.900]\n",
      "Epoch 4:  47%|████▋     | 47/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.191, loss=0.0253, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  48%|████▊     | 48/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.191, loss=0.0253, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  48%|████▊     | 48/100 [00:08<00:09,  5.66it/s, lr=1e-5, sum_loss=0.188, loss=0.0635, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 4:  49%|████▉     | 49/100 [00:08<00:08,  5.67it/s, lr=1e-5, sum_loss=0.188, loss=0.0635, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 4:  49%|████▉     | 49/100 [00:08<00:08,  5.67it/s, lr=1e-5, sum_loss=0.196, loss=0.594, REAL it/s=5.960, Kt/s=3.050] \n",
      "Epoch 4:  50%|█████     | 50/100 [00:08<00:08,  5.68it/s, lr=1e-5, sum_loss=0.196, loss=0.594, REAL it/s=5.960, Kt/s=3.050]\n",
      "Epoch 4:  50%|█████     | 50/100 [00:08<00:08,  5.68it/s, lr=1e-5, sum_loss=0.197, loss=0.244, REAL it/s=6.040, Kt/s=3.090]\n",
      "Epoch 4:  51%|█████     | 51/100 [00:08<00:08,  5.68it/s, lr=1e-5, sum_loss=0.197, loss=0.244, REAL it/s=6.040, Kt/s=3.090]\n",
      "Epoch 4:  51%|█████     | 51/100 [00:08<00:08,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.0337, REAL it/s=5.870, Kt/s=3.010]\n",
      "Epoch 4:  52%|█████▏    | 52/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.0337, REAL it/s=5.870, Kt/s=3.010]\n",
      "Epoch 4:  52%|█████▏    | 52/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.191, loss=0.0231, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  53%|█████▎    | 53/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.191, loss=0.0231, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  53%|█████▎    | 53/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.188, loss=0.0109, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 4:  54%|█████▍    | 54/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.188, loss=0.0109, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 4:  54%|█████▍    | 54/100 [00:09<00:08,  5.68it/s, lr=1e-5, sum_loss=0.184, loss=0.012, REAL it/s=5.770, Kt/s=2.950] \n",
      "Epoch 4:  55%|█████▌    | 55/100 [00:09<00:07,  5.68it/s, lr=1e-5, sum_loss=0.184, loss=0.012, REAL it/s=5.770, Kt/s=2.950]\n",
      "Epoch 4:  55%|█████▌    | 55/100 [00:09<00:07,  5.68it/s, lr=1e-5, sum_loss=0.182, loss=0.0491, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  56%|█████▌    | 56/100 [00:09<00:07,  5.68it/s, lr=1e-5, sum_loss=0.182, loss=0.0491, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  56%|█████▌    | 56/100 [00:09<00:07,  5.68it/s, lr=1e-5, sum_loss=0.179, loss=0.00549, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 4:  57%|█████▋    | 57/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.179, loss=0.00549, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 4:  57%|█████▋    | 57/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.178, loss=0.149, REAL it/s=5.660, Kt/s=2.900]  \n",
      "Epoch 4:  58%|█████▊    | 58/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.178, loss=0.149, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  58%|█████▊    | 58/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.193, loss=1.050, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 4:  59%|█████▉    | 59/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.193, loss=1.050, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 4:  59%|█████▉    | 59/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.189, loss=0.0287, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 4:  60%|██████    | 60/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.189, loss=0.0287, REAL it/s=5.750, Kt/s=2.940]\n",
      "Epoch 4:  60%|██████    | 60/100 [00:10<00:07,  5.68it/s, lr=1e-5, sum_loss=0.188, loss=0.118, REAL it/s=5.580, Kt/s=2.860] \n",
      "Epoch 4:  61%|██████    | 61/100 [00:10<00:06,  5.68it/s, lr=1e-5, sum_loss=0.188, loss=0.118, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 4:  61%|██████    | 61/100 [00:10<00:06,  5.68it/s, lr=1e-5, sum_loss=0.204, loss=1.110, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 4:  62%|██████▏   | 62/100 [00:10<00:06,  5.68it/s, lr=1e-5, sum_loss=0.204, loss=1.110, REAL it/s=5.610, Kt/s=2.870]\n",
      "Epoch 4:  62%|██████▏   | 62/100 [00:10<00:06,  5.68it/s, lr=1e-5, sum_loss=0.200, loss=0.0172, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  63%|██████▎   | 63/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.200, loss=0.0172, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  63%|██████▎   | 63/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.197, loss=0.00258, REAL it/s=5.710, Kt/s=2.930]\n",
      "Epoch 4:  64%|██████▍   | 64/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.197, loss=0.00258, REAL it/s=5.710, Kt/s=2.930]\n",
      "Epoch 4:  64%|██████▍   | 64/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.064, REAL it/s=5.730, Kt/s=2.930]  \n",
      "Epoch 4:  65%|██████▌   | 65/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.064, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 4:  65%|██████▌   | 65/100 [00:11<00:06,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.163, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 4:  66%|██████▌   | 66/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.195, loss=0.163, REAL it/s=5.630, Kt/s=2.880]\n",
      "Epoch 4:  66%|██████▌   | 66/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.193, loss=0.0732, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  67%|██████▋   | 67/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.193, loss=0.0732, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  67%|██████▋   | 67/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.190, loss=0.0255, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  68%|██████▊   | 68/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.190, loss=0.0255, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  68%|██████▊   | 68/100 [00:11<00:05,  5.68it/s, lr=1e-5, sum_loss=0.188, loss=0.0459, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  69%|██████▉   | 69/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.188, loss=0.0459, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  69%|██████▉   | 69/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.187, loss=0.0884, REAL it/s=5.990, Kt/s=3.070]\n",
      "Epoch 4:  70%|███████   | 70/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.187, loss=0.0884, REAL it/s=5.990, Kt/s=3.070]\n",
      "Epoch 4:  70%|███████   | 70/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.187, loss=0.188, REAL it/s=5.970, Kt/s=3.060] \n",
      "Epoch 4:  71%|███████   | 71/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.187, loss=0.188, REAL it/s=5.970, Kt/s=3.060]\n",
      "Epoch 4:  71%|███████   | 71/100 [00:12<00:05,  5.69it/s, lr=1e-5, sum_loss=0.184, loss=0.0234, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 4:  72%|███████▏  | 72/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.184, loss=0.0234, REAL it/s=5.920, Kt/s=3.030]\n",
      "Epoch 4:  72%|███████▏  | 72/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.182, loss=0.0211, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  73%|███████▎  | 73/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.182, loss=0.0211, REAL it/s=5.910, Kt/s=3.030]\n",
      "Epoch 4:  73%|███████▎  | 73/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.180, loss=0.0781, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  74%|███████▍  | 74/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.180, loss=0.0781, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  74%|███████▍  | 74/100 [00:12<00:04,  5.70it/s, lr=1e-5, sum_loss=0.181, loss=0.225, REAL it/s=5.910, Kt/s=3.020] \n",
      "Epoch 4:  75%|███████▌  | 75/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.181, loss=0.225, REAL it/s=5.910, Kt/s=3.020]\n",
      "Epoch 4:  75%|███████▌  | 75/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.179, loss=0.0128, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:  76%|███████▌  | 76/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.179, loss=0.0128, REAL it/s=5.800, Kt/s=2.970]\n",
      "Epoch 4:  76%|███████▌  | 76/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.179, loss=0.167, REAL it/s=5.790, Kt/s=2.970] \n",
      "Epoch 4:  77%|███████▋  | 77/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.179, loss=0.167, REAL it/s=5.790, Kt/s=2.970]\n",
      "Epoch 4:  77%|███████▋  | 77/100 [00:13<00:04,  5.70it/s, lr=1e-5, sum_loss=0.178, loss=0.146, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  78%|███████▊  | 78/100 [00:13<00:03,  5.70it/s, lr=1e-5, sum_loss=0.178, loss=0.146, REAL it/s=5.660, Kt/s=2.900]\n",
      "Epoch 4:  78%|███████▊  | 78/100 [00:13<00:03,  5.70it/s, lr=1e-5, sum_loss=0.176, loss=0.0239, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 4:  79%|███████▉  | 79/100 [00:13<00:03,  5.70it/s, lr=1e-5, sum_loss=0.176, loss=0.0239, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 4:  79%|███████▉  | 79/100 [00:13<00:03,  5.70it/s, lr=1e-5, sum_loss=0.173, loss=0.00525, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 4:  80%|████████  | 80/100 [00:14<00:03,  5.70it/s, lr=1e-5, sum_loss=0.173, loss=0.00525, REAL it/s=5.690, Kt/s=2.910]\n",
      "Epoch 4:  80%|████████  | 80/100 [00:14<00:03,  5.70it/s, lr=1e-5, sum_loss=0.172, loss=0.0547, REAL it/s=5.820, Kt/s=2.980] \n",
      "Epoch 4:  81%|████████  | 81/100 [00:14<00:03,  5.70it/s, lr=1e-5, sum_loss=0.172, loss=0.0547, REAL it/s=5.820, Kt/s=2.980]\n",
      "Epoch 4:  81%|████████  | 81/100 [00:14<00:03,  5.70it/s, lr=1e-5, sum_loss=0.171, loss=0.0981, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  82%|████████▏ | 82/100 [00:14<00:03,  5.71it/s, lr=1e-5, sum_loss=0.171, loss=0.0981, REAL it/s=5.720, Kt/s=2.930]\n",
      "Epoch 4:  82%|████████▏ | 82/100 [00:14<00:03,  5.71it/s, lr=1e-5, sum_loss=0.169, loss=0.0243, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 4:  83%|████████▎ | 83/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.169, loss=0.0243, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 4:  83%|████████▎ | 83/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.168, loss=0.0522, REAL it/s=5.850, Kt/s=3.000]\n",
      "Epoch 4:  84%|████████▍ | 84/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.168, loss=0.0522, REAL it/s=5.850, Kt/s=3.000]\n",
      "Epoch 4:  84%|████████▍ | 84/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.166, loss=0.00583, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 4:  85%|████████▌ | 85/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.166, loss=0.00583, REAL it/s=5.780, Kt/s=2.960]\n",
      "Epoch 4:  85%|████████▌ | 85/100 [00:14<00:02,  5.71it/s, lr=1e-5, sum_loss=0.165, loss=0.0635, REAL it/s=5.740, Kt/s=2.940] \n",
      "Epoch 4:  86%|████████▌ | 86/100 [00:15<00:02,  5.71it/s, lr=1e-5, sum_loss=0.165, loss=0.0635, REAL it/s=5.740, Kt/s=2.940]\n",
      "Epoch 4:  86%|████████▌ | 86/100 [00:15<00:02,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.268, REAL it/s=5.480, Kt/s=2.800] \n",
      "Epoch 4:  87%|████████▋ | 87/100 [00:15<00:02,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.268, REAL it/s=5.480, Kt/s=2.800]\n",
      "Epoch 4:  87%|████████▋ | 87/100 [00:15<00:02,  5.70it/s, lr=1e-5, sum_loss=0.168, loss=0.391, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 4:  88%|████████▊ | 88/100 [00:15<00:02,  5.70it/s, lr=1e-5, sum_loss=0.168, loss=0.391, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 4:  88%|████████▊ | 88/100 [00:15<00:02,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.00386, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  89%|████████▉ | 89/100 [00:15<00:01,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.00386, REAL it/s=5.640, Kt/s=2.890]\n",
      "Epoch 4:  89%|████████▉ | 89/100 [00:15<00:01,  5.70it/s, lr=1e-5, sum_loss=0.164, loss=0.0292, REAL it/s=5.760, Kt/s=2.950] \n",
      "Epoch 4:  90%|█████████ | 90/100 [00:15<00:01,  5.71it/s, lr=1e-5, sum_loss=0.164, loss=0.0292, REAL it/s=5.760, Kt/s=2.950]\n",
      "Epoch 4:  90%|█████████ | 90/100 [00:15<00:01,  5.71it/s, lr=1e-5, sum_loss=0.162, loss=0.00995, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  91%|█████████ | 91/100 [00:15<00:01,  5.71it/s, lr=1e-5, sum_loss=0.162, loss=0.00995, REAL it/s=5.880, Kt/s=3.010]\n",
      "Epoch 4:  91%|█████████ | 91/100 [00:15<00:01,  5.71it/s, lr=1e-5, sum_loss=0.170, loss=0.852, REAL it/s=5.870, Kt/s=3.010]  \n",
      "Epoch 4:  92%|█████████▏| 92/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.170, loss=0.852, REAL it/s=5.870, Kt/s=3.010]\n",
      "Epoch 4:  92%|█████████▏| 92/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.169, loss=0.0352, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 4:  93%|█████████▎| 93/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.169, loss=0.0352, REAL it/s=5.730, Kt/s=2.930]\n",
      "Epoch 4:  93%|█████████▎| 93/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.167, loss=0.0225, REAL it/s=5.670, Kt/s=2.900]\n",
      "Epoch 4:  94%|█████████▍| 94/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.167, loss=0.0225, REAL it/s=5.670, Kt/s=2.900]\n",
      "Epoch 4:  94%|█████████▍| 94/100 [00:16<00:01,  5.71it/s, lr=1e-5, sum_loss=0.172, loss=0.535, REAL it/s=5.560, Kt/s=2.850] \n",
      "Epoch 4:  95%|█████████▌| 95/100 [00:16<00:00,  5.70it/s, lr=1e-5, sum_loss=0.172, loss=0.535, REAL it/s=5.560, Kt/s=2.850]\n",
      "Epoch 4:  95%|█████████▌| 95/100 [00:16<00:00,  5.70it/s, lr=1e-5, sum_loss=0.170, loss=0.00291, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 4:  96%|█████████▌| 96/100 [00:16<00:00,  5.70it/s, lr=1e-5, sum_loss=0.170, loss=0.00291, REAL it/s=5.520, Kt/s=2.830]\n",
      "Epoch 4:  96%|█████████▌| 96/100 [00:16<00:00,  5.70it/s, lr=1e-5, sum_loss=0.168, loss=0.00121, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 4:  97%|█████████▋| 97/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.168, loss=0.00121, REAL it/s=5.580, Kt/s=2.860]\n",
      "Epoch 4:  97%|█████████▋| 97/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.0315, REAL it/s=5.570, Kt/s=2.850] \n",
      "Epoch 4:  98%|█████████▊| 98/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.0315, REAL it/s=5.570, Kt/s=2.850]\n",
      "Epoch 4:  98%|█████████▊| 98/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.0771, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 4:  99%|█████████▉| 99/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.166, loss=0.0771, REAL it/s=5.600, Kt/s=2.870]\n",
      "Epoch 4:  99%|█████████▉| 99/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.177, loss=1.290, REAL it/s=5.650, Kt/s=2.890] \n",
      "Epoch 4: 100%|██████████| 100/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.177, loss=1.290, REAL it/s=5.650, Kt/s=2.890]\n",
      "Epoch 4: 100%|██████████| 100/100 [00:17<00:00,  5.70it/s, lr=1e-5, sum_loss=0.175, loss=0.00629, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 4: 100%|██████████| 100/100 [00:17<00:00,  5.68it/s, lr=1e-5, sum_loss=0.175, loss=0.00629, REAL it/s=5.550, Kt/s=2.840]\n",
      "Epoch 4: 100%|██████████| 100/100 [00:17<00:00,  5.68it/s, lr=1e-5, sum_loss=0.175, loss=0.00629, REAL it/s=5.550, Kt/s=2.840]\n",
      "\n",
      "⚠️ STDERR:\n",
      " ########## work in progress ##########\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "Using /home/re2230/.cache/torch_extensions/py310_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/re2230/.cache/torch_extensions/py310_cu126/wkv5/build.ninja...\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module wkv5...\n",
      "########## Loading /home/re2230/.cache/huggingface/hub/models--RWKV--rwkv-5-world-all-pth/snapshots/d48d1c54cf32cfdc13fca3c767998a0bf3eef8b6/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth... ##########\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/lightning/fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "Using /home/re2230/.cache/torch_extensions/py310_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/re2230/.cache/torch_extensions/py310_cu126/fused_adam/build.ninja...\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module fused_adam...\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | RWKV5            | 469 M  | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "8.6 M     Trainable params\n",
      "461 M     Non-trainable params\n",
      "469 M     Total params\n",
      "1,879.917 Total estimated model params size (MB)\n",
      "391       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/re2230/rwkv-env/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "[rank0]:[W527 11:00:42.655291094 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "\n",
      "✅ Training started successfully\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import os\n",
    "\n",
    "# Activar seguimiento en Weights & Biases\n",
    "os.environ[\"WANDB_PROJECT\"] = \"rwkv-finetune\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"modbus_dataset.jsonl\")\n",
    "\n",
    "model_path = \"/home/re2230/.cache/huggingface/hub/models--RWKV--rwkv-5-world-all-pth/snapshots/d48d1c54cf32cfdc13fca3c767998a0bf3eef8b6/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth\"\n",
    "\n",
    "command = f\"\"\"\n",
    "python RWKV-PEFT/train.py \\\n",
    "--load_model {model_path} \\\n",
    "--data_file json \\\n",
    "--data_files /home/re2230/modbus_dataset.jsonl \\\n",
    "--data_type sft \\\n",
    "--sft_field query response \\\n",
    "--ctx_len 512 \\\n",
    "--epoch_steps 100 \\\n",
    "--epoch_count 5 \\\n",
    "--micro_bsz 1 \\\n",
    "--n_layer 24 \\\n",
    "--n_embd 1024 \\\n",
    "--vocab_size 65536 \\\n",
    "--lr_init 6e-5 \\\n",
    "--warmup_steps 10 \\\n",
    "--strategy deepspeed \\\n",
    "--accelerator cuda \\\n",
    "--precision bf16 \\\n",
    "--peft disha \\\n",
    "--disha_config '{{\"mode\":\"bone\",\"r\":32,\"load\":\"\"}}' \\\n",
    "--proj_dir out/rwkv-modbus-ft\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = subprocess.run(shlex.split(command), capture_output=True, text=True)\n",
    "\n",
    "print(\"📤 STDOUT:\\n\", result.stdout)\n",
    "print(\"⚠️ STDERR:\\n\", result.stderr)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(f\"❌ Training failed with exit code {result.returncode}\")\n",
    "else:\n",
    "    print(\"✅ Training started successfully\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f8ba8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/re2230/RWKV-PEFT/rwkvt/dataset\")  # change to your actual path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa8d891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 🔧 Variables de entorno necesarias para RWKV-PEFT\n",
    "os.environ[\"RWKV_HEAD_SIZE_A\"] = \"64\"\n",
    "os.environ[\"RWKV_MY_TESTING\"] = \"x052\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1485aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "########## Loading /home/re2230/out/rwkv-modbus-ft/rwkv-4.pth... ##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV(\n",
      "  (model): RWKV5(\n",
      "    (emb): Embedding(65536, 1024)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=1024, out_features=65536, bias=False)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "✅ Accuracy (BCA): 0.0000 (0/160)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from rwkvt.peft.peft_loading import load_peft_model\n",
    "from rwkvt.args_type import TrainingArgs\n",
    "from rwkv.utils import PIPELINE\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "EOT_TOKEN = \"\\x17\"\n",
    "PROMPT = (\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    ")\n",
    "\n",
    "# ⚙️ Setup model args\n",
    "args = TrainingArgs()\n",
    "args.load_model = \"/home/re2230/out/rwkv-modbus-ft/rwkv-4.pth\"\n",
    "args.strategy = \"cuda bf16\"\n",
    "args.ctx_len = 512\n",
    "args.peft = \"disha\"\n",
    "args.n_layer = 24\n",
    "args.n_embd = 1024\n",
    "args.vocab_size = 65536\n",
    "args.dim_att = 1024\n",
    "args.dim_ffn = 3584\n",
    "args.head_size_a = 64\n",
    "args.head_size_divisor = 8\n",
    "os.environ[\"RWKV_HEAD_SIZE_A\"] = str(args.head_size_a)\n",
    "args.disha_config = {\"mode\": \"bone\", \"r\": 32, \"load\": \"\"}\n",
    "os.environ[\"RWKV_MY_TESTING\"] = \"x052\"\n",
    "os.environ[\"RWKV_HEAD_SIZE_A\"] = \"64\"\n",
    "os.environ[\"RWKV_TRAIN_TYPE\"] = \"sft\"\n",
    "\n",
    "# 🧪 Evaluation loop\n",
    "args, model = load_peft_model(args)\n",
    "model = model.to(dtype=torch.bfloat16, device=\"cuda\").eval()\n",
    "\n",
    "# model.eval().cuda()\n",
    "\n",
    "# 🧠 Cargar tokenizer (misma ruta usada en entrenamiento)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-5-world-3b\", trust_remote_code=True)\n",
    "\n",
    "# 📄 Evaluación con archivo jsonl\n",
    "PROMPT = (\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    ")\n",
    "\n",
    "test_file = \"/home/re2230/RWKV-PEFT/rwkvt/dataset/modbus_dataset_test.jsonl\"\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with open(test_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        prompt = PROMPT.format_map({\"instruction\": item[\"query\"]})\n",
    "        expected = item[\"response\"]\n",
    "\n",
    "        # 🔁 Tokenizar\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "        # 🔮 Inferencia\n",
    "# 🔮 Inferencia\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")  # Mantener como int64\n",
    "\n",
    "            # El modelo automáticamente opera en bfloat16 si se cargó con strategy=\"cuda bf16\"\n",
    "            logits = model(input_ids)[0]\n",
    "            pred_ids = torch.argmax(logits, dim=-1)\n",
    "            output = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # 🎯 Comparación exacta\n",
    "        if output.strip() == expected.strip():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print(f\"✅ Accuracy (BCA): {correct / total:.4f} ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c156d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy (BCA): 0.0000 (0/160)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "test_file = \"/home/re2230/RWKV-PEFT/rwkvt/dataset/modbus_dataset_test.jsonl\"\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "output_file = Path(\"modbus_predictions.txt\")\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    out_f.write(\"Prompt\\tExpected\\tPredicted\\tMatch\\n\")\n",
    "\n",
    "with open(test_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        prompt = PROMPT.format_map({\"instruction\": item[\"query\"]})\n",
    "        expected = item[\"response\"]\n",
    "\n",
    "        # 🔁 Tokenizar\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "        # 🔮 Inferencia\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")  # Mantener como int64\n",
    "\n",
    "            # El modelo automáticamente opera en bfloat16 si se cargó con strategy=\"cuda bf16\"\n",
    "            logits = model(input_ids)[0]\n",
    "            pred_ids = torch.argmax(logits, dim=-1)\n",
    "            output = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            match = output.strip() == expected.strip()\n",
    "            if match:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            # Save to file\n",
    "            with open(output_file, \"a\") as out_f:\n",
    "                out_f.write(f\"{item['query']}\\t{expected.strip()}\\t{output.strip()}\\t{match}\\n\")\n",
    "\n",
    "\n",
    "print(f\"✅ Accuracy (BCA): {correct / total:.4f} ({correct}/{total})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d502f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "✅ Accuracy (BCA): 0.0000 (0/160)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "\n",
    "test_file = \"/home/re2230/RWKV-PEFT/rwkvt/dataset/modbus_dataset_test.jsonl\"\n",
    "output_file = Path(\"modbus_predictions.txt\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Define column widths\n",
    "col_widths = {\n",
    "    \"prompt\": 40,\n",
    "    \"expected\": 40,\n",
    "    \"predicted\": 40,\n",
    "    \"match\": 7,\n",
    "}\n",
    "\n",
    "# Write header\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    header = f\"{'Prompt'.ljust(col_widths['prompt'])} | {'Expected'.ljust(col_widths['expected'])} | {'Predicted'.ljust(col_widths['predicted'])} | {'Match'}\\n\"\n",
    "    out_f.write(header)\n",
    "    out_f.write(\"-\" * len(header) + \"\\n\")\n",
    "\n",
    "# Inference loop\n",
    "with open(test_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        prompt = PROMPT.format_map({\"instruction\": item[\"query\"]})\n",
    "        expected = item[\"response\"]\n",
    "\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids)[0]\n",
    "            pred_ids = torch.argmax(logits, dim=-1)\n",
    "            output = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "            print(output.strip())\n",
    "\n",
    "        match = output.strip() == expected.strip()\n",
    "        if match:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "        # Truncate long values for readability\n",
    "        q = item['query'][:col_widths[\"prompt\"] - 3] + \"...\" if len(item['query']) > col_widths[\"prompt\"] else item['query']\n",
    "        e = expected.strip()[:col_widths[\"expected\"] - 3] + \"...\" if len(expected.strip()) > col_widths[\"expected\"] else expected.strip()\n",
    "        p = output.strip()[:col_widths[\"predicted\"] - 3] + \"...\" if len(output.strip()) > col_widths[\"predicted\"] else output.strip()\n",
    "\n",
    "        with open(output_file, \"a\") as out_f:\n",
    "            row = f\"{q.ljust(col_widths['prompt'])} | {e.ljust(col_widths['expected'])} | {p.ljust(col_widths['predicted'])} | {str(match)}\\n\"\n",
    "            out_f.write(row)\n",
    "\n",
    "print(f\"✅ Accuracy (BCA): {correct / total:.4f} ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ebf97edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "########## Loading /home/re2230/out/rwkv-modbus-ft/rwkv-4.pth... ##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV(\n",
      "  (model): RWKV5(\n",
      "    (emb): Embedding(65536, 1024)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=1024, out_features=65536, bias=False)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "✅ Accuracy (BCA): 0.0000 (0/160)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from rwkvt.peft.peft_loading import load_peft_model\n",
    "from rwkvt.args_type import TrainingArgs\n",
    "from pathlib import Path\n",
    "\n",
    "# === Setup fine-tuned model ===\n",
    "args = TrainingArgs()\n",
    "args.load_model = \"/home/re2230/out/rwkv-modbus-ft/rwkv-4.pth\"\n",
    "args.strategy = \"cuda bf16\"\n",
    "args.ctx_len = 512\n",
    "args.peft = \"disha\"\n",
    "args.n_layer = 24\n",
    "args.n_embd = 1024\n",
    "args.vocab_size = 65536\n",
    "args.dim_att = 1024\n",
    "args.dim_ffn = 3584\n",
    "args.head_size_a = 64\n",
    "args.head_size_divisor = 8\n",
    "args.disha_config = {\"mode\": \"bone\", \"r\": 32, \"load\": \"\"}\n",
    "\n",
    "# Required env vars\n",
    "os.environ[\"RWKV_MY_TESTING\"] = \"x052\"\n",
    "os.environ[\"RWKV_HEAD_SIZE_A\"] = str(args.head_size_a)\n",
    "os.environ[\"RWKV_TRAIN_TYPE\"] = \"sft\"\n",
    "\n",
    "# Load model\n",
    "args, model = load_peft_model(args)\n",
    "model = model.eval().cuda().to(dtype=torch.bfloat16)\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-5-world-3b\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Prompt template\n",
    "PROMPT = (\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_file = \"/home/re2230/RWKV-PEFT/rwkvt/dataset/modbus_dataset_test.jsonl\"\n",
    "output_file = Path(\"modbus_predictions_2.txt\")\n",
    "correct, total = 0, 0\n",
    "\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    out_f.write(\"Prompt\\tExpected\\tPredicted\\tMatch\\n\")\n",
    "\n",
    "    with open(test_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            prompt_text = PROMPT.format_map({\"instruction\": item[\"query\"]})\n",
    "            expected = item[\"response\"]\n",
    "\n",
    "            # Encode and initialize sequence\n",
    "            input_ids = tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"].to(device=\"cuda\")  # 🟢 Keep int64!\n",
    "            generated = input_ids.clone()\n",
    "\n",
    "            # Greedy decoding\n",
    "            for _ in range(len(expected) + 4):\n",
    "                with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                    logits = model(generated)[0]\n",
    "                    next_token_logits = logits[-1, :]\n",
    "                    next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0).unsqueeze(0)\n",
    "                    generated = torch.cat([generated, next_token_id], dim=1)\n",
    "\n",
    "                    if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                        break\n",
    "\n",
    "            # Decode predicted\n",
    "            predicted_text = tokenizer.decode(generated[0][input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "            match = predicted_text == expected.strip()\n",
    "\n",
    "            if match:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            # Write result\n",
    "            out_f.write(f\"{item['query']}\\t{expected.strip()}\\t{predicted_text}\\t{match}\\n\")\n",
    "\n",
    "print(f\"✅ Accuracy (BCA): {correct / total:.4f} ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "41319f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "########## Loading /home/re2230/out/rwkv-modbus-ft/rwkv-4.pth... ##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV(\n",
      "  (model): RWKV5(\n",
      "    (emb): Embedding(65536, 1024)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x Block(\n",
      "        (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (att): RWKV_TimeMix_RWKV5(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (receptance): BoneLinear()\n",
      "          (key): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "          (output): BoneLinear()\n",
      "          (gate): BoneLinear()\n",
      "          (ln_x): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (ffn): RWKV_ChannelMix(\n",
      "          (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
      "          (key): BoneLinear()\n",
      "          (receptance): BoneLinear()\n",
      "          (value): BoneLinear()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): Linear(in_features=1024, out_features=65536, bias=False)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "✅ Accuracy (Exact Match): 0.0000 (0/160)\n",
      "📄 Predictions saved to: /home/re2230/modbus_predictions_log.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "from rwkvt.peft.peft_loading import load_peft_model\n",
    "from rwkvt.args_type import TrainingArgs\n",
    "\n",
    "# === Model Setup ===\n",
    "args = TrainingArgs()\n",
    "args.load_model = \"/home/re2230/out/rwkv-modbus-ft/rwkv-4.pth\"\n",
    "args.strategy = \"cuda bf16\"\n",
    "args.ctx_len = 512\n",
    "args.peft = \"disha\"\n",
    "args.n_layer = 24\n",
    "args.n_embd = 1024\n",
    "args.vocab_size = 65536\n",
    "args.dim_att = 1024\n",
    "args.dim_ffn = 3584\n",
    "args.head_size_a = 64\n",
    "args.head_size_divisor = 8\n",
    "args.disha_config = {\"mode\": \"bone\", \"r\": 32, \"load\": \"\"}\n",
    "\n",
    "# === Environment Variables ===\n",
    "os.environ[\"RWKV_MY_TESTING\"] = \"x052\"\n",
    "os.environ[\"RWKV_HEAD_SIZE_A\"] = str(args.head_size_a)\n",
    "os.environ[\"RWKV_TRAIN_TYPE\"] = \"sft\"\n",
    "\n",
    "# === Load Model ===\n",
    "args, model = load_peft_model(args)\n",
    "model = model.eval().to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "\n",
    "# === Load Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-5-world-3b\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Optional\n",
    "\n",
    "# === Prompt Template ===\n",
    "PROMPT = (\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    ")\n",
    "\n",
    "# === Evaluation ===\n",
    "test_file = \"/home/re2230/RWKV-PEFT/rwkvt/dataset/modbus_dataset_test.jsonl\"\n",
    "output_file = Path(\"modbus_predictions_log.tsv\")\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with open(test_file, \"r\") as f, open(output_file, \"w\") as out_f:\n",
    "    out_f.write(\"Prompt\\tExpected\\tPredicted\\tMatch\\n\")\n",
    "    out_f.write(\"=\" * 150 + \"\\n\")\n",
    "\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        instruction = item[\"query\"]\n",
    "        expected = item[\"response\"].strip()\n",
    "        prompt_text = PROMPT.format(instruction=instruction)\n",
    "\n",
    "        # Tokenize once\n",
    "        input_ids = tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids)[0]  # RWKV returns [seq_len, vocab_size]\n",
    "            pred_ids = torch.argmax(logits, dim=-1)\n",
    "            predicted_text = tokenizer.decode(pred_ids[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        match = predicted_text == expected\n",
    "        correct += int(match)\n",
    "        total += 1\n",
    "\n",
    "        # Log tabular result\n",
    "        out_f.write(f\"{instruction}\\t{expected}\\t{predicted_text}\\t{match}\\n\")\n",
    "\n",
    "# === Final Score ===\n",
    "print(f\"✅ Accuracy (Exact Match): {correct / total:.4f} ({correct}/{total})\")\n",
    "print(f\"📄 Predictions saved to: {output_file.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RWKV (Hydra)",
   "language": "python",
   "name": "rwkv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
